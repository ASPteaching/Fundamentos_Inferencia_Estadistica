[
  {
    "objectID": "01-probabilidad.html",
    "href": "01-probabilidad.html",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "",
    "text": "1.1 Introducción",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "01-probabilidad.html#introducción",
    "href": "01-probabilidad.html#introducción",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "",
    "text": "1.1.1 Fenómenos deterministas y fenómenos aleatorios\nSupongamos que disponemos de un dado regular con todas las caras pintadas de blanco y con un número, que irá de 1 a \\(6 \\sin\\) repetir ninguno, en cada una de las seis caras.\nDefinamos los dos experimentos siguientes: Experimento 1: Tirar el dado y anotar el color de la cara resultante. Experimento 2: Tirar el dado y anotar el número de la cara resultante. ¿Qué diferencia fundamental observamos entre ambos experimentos? Muy simple! En el experimento 1, el resultado es obvio: saldrá una cara de color blanco. Es decir, es posible predecir el resultado. Se trata de un experimento o fenómeno determinista.\nEn cambio, en el experimento 2 no podemos predecir cuál será el valor resultante. El resultado puede ser : \\(1,2,3,4,5\\) o 6 . Se trata de un experimento o fenómeno aleatorio.\nEl conjunto de resultados se anotará con el símbolo: \\(\\Omega\\). En este caso, \\(\\Omega=\\{1,2,3,4,5,6\\}\\). En los fenómenos aleatorios, al hacer muchas veces la experiencia, la frecuencia relativa de cualquier elemento del conjunto de resultados debe aproximarse siempre hacia un mismo valor.\n\n\n1.1.2 Sucesos\nSupongamos que se ejecuta un experimento aleatorio. Se nos puede ocurrir emitir un enunciado que, una vez realizada la experiencia, pueda decirse si se ha verificado o no se ha verificado. A dichos enunciados los denominamos sucesos.\nPor otro lado, los sucesos van asociados a subconjuntos del conjunto de resultados. Cada suceso se corresponderá exactamente con uno, y sólo con un, subconjunto del conjunto de resultados.\nVeamos un ejemplo: Experimento: Tirar un dado regular. Conjunto de resultados : \\(\\Omega=\\{1,2,3,4,5,6\\}\\) Enunciado: Obtener múltiplo de 3. Subconjunto al que se asocia el enunciado: \\(A=\\{3,6\\}\\) Nos referiremos habitualmente al suceso A.\n\n1.1.2.1 Sucesos y conjuntos\nAl conjunto de resultados \\(\\Omega\\), se le denomina suceso seguro. Al conjunto Ø ( conjunto sin elementos), se le denomina suceso imposible. Al complementario del conjunto \\(\\mathrm{A}\\left(\\mathrm{A}^{\\mathrm{c}}\\right)\\), se le denomina suceso contrario o complementario de \\(A\\). A partir de dos sucesos A y B, podemos formar los sucesos siguientes:\n\nA intersección B, que anotaremos como:\n\n\\[\nA \\cap B\n\\]\n\nA unión B, que anotaremos como:\n\n\\[\nA \\cup B\n\\]\nA intersección B, significa que se verifican a la vez A y B. A unión B, significa que se verifica \\(A\\) o \\(B\\) ( se pueden verificar a la vez).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "01-probabilidad.html#función-de-probabilidad",
    "href": "01-probabilidad.html#función-de-probabilidad",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "1.2 Función de probabilidad",
    "text": "1.2 Función de probabilidad\nLógicamente, una vez tenemos un suceso, nos preocupa saber si hay muchas o pocas posibilidades de que al realizar la experiencia se haya verificado.\nPor lo tanto, sería interesante el tener alguna función que midiera el grado de confianza a depositar en que se verifique el suceso.\nA esta función la denominaremos función de probabilidad. La función de probabilidad será, pues, una aplicación entre el conjunto de resultados y el conjunto de números reales, que asignará a cada suceso la probabilidad de que se verifique.\nLa notación: \\(\\mathrm{P}(\\mathrm{A})\\) significará: probabilidad de que se verifique el suceso A . Pero claro, de funciones de probabilidad asociadas a priori a una experiencia aleatoria podrían haber muchas.\nLo que se hace para decir qué es y qué no es una función de probabilidad es construir una serie de propiedades (denominadas axiomas) que se exigirán a una función para poder ser catalogada como función de probabilidad.\nY, ¿cuáles son estos axiomas? Pues los siguientes: Sea S el conjunto de sucesos. Axioma 1: Para cualquier suceso A, la probabilidad debe ser mayor o igual que 0 . Axioma 2: \\(\\mathrm{P}(\\Omega)=1\\) Axioma 3: Para sucesos \\(\\mathrm{A}_{\\mathrm{i}}\\), de modo que cada par de sucesos no tengan ningún resultado común, se verifica que:\n\\[\nP\\left(\\bigcup_{i=1}^{\\infty} A_{i}\\right)=\\sum_{i=1}^{\\infty} P\\left(A_{i}\\right)\n\\]\nDe este modo, pueden haber muchas funciones de probabilidad que se podrían asociar con la experiencia.\nEl problema pasa entonces al investigador para decidir cual o cuales son las funciones de probabilidad más razonables asociadas con la experiencia que está manejando.\n\n1.2.1 ¿Diferentes funciones de probabilidad para una misma experiencia aleatoria?\nSupongamos la experiencia de tirar un dado regular. A todo el mundo se le ocurriría pensar que la función de probabilidad se obtiene de contar el número de resultados que contiene el suceso dividido por 6 , que es el número total de resultados posibles. Así pues, la probabilidad de obtener un múltiplo de 3 sería igual a \\(2 / 6\\), la probabilidad de obtener el número 2 sería \\(1 / 6\\) i la probabilidad de obtener un número par sería 3/6. Es decir, parece inmediato construir la función de probabilidad que, además, parece única. A nadie se le ocurre decir, por ejemplo, que la probabilidad de obtener un número par es \\(5 / 6\\) !\nEn este caso, todo ha sido muy fácil. Hemos visto que existe una única función de probabilidad que encaje de forma lógica con la experiencia y, además, ha sido muy sencillo encontrarla.\nPero esto, por desgracia, no siempre es así. En muchísimas ocasiones resulta muy complejo el decidir cuál es la función de probabilidad.\nEn el tema de variables aleatorias y de función de distribución se explica el problema de la modelización de muchas situaciones reales.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "01-probabilidad.html#cómo-se-calculan-las-probabilidades",
    "href": "01-probabilidad.html#cómo-se-calculan-las-probabilidades",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "1.3 ¿Cómo se calculan las probabilidades?",
    "text": "1.3 ¿Cómo se calculan las probabilidades?\nNo siempre es fácil conocer los valores de la función de probabilidad de todos los sucesos. Sin embargo, muchas veces se pueden conocer las probabilidades de algunos de estos sucesos. Con la ayuda de ciertas propiedades que se deducen de manera inmediata a partir de la axiomática es posible calcular las probabilidades de más sucesos.\nPor otro lado, en caso de que el número de resultados sea finito y de que todos los resultados tengan las mismas posibilidades de verificarse, la probabilidad de un suceso cualquiera se puede calcular a partir de la regla de Laplace:\nSi A es un suceso :\n\\[\n\\text { Probabilidad }(A)=\\frac{\\text { Número de casos favorables }}{\\text { Número de casos posibles }}\n\\]\ndonde: Número de casos favorables \\(=\\) Número de resultados contenidos en \\(\\mathrm{A}(\\) cardinal de A\\()\\) Número de casos posibles \\(=\\) Número total de resultados posibles (cardinal del conjunto total de resultados)\nEn este caso, el contar número de resultados, ya sean favorables o posibles, debe hacerse por medio de la combinatoria.\nVeamos con unos ejemplos muy sencillos y visuales cómo se obtienen y qué representan los casos posibles y los casos favorables.\n\n\n\n\n\n\n\n\n\n\n\nTambién es posible obtener de manera aproximada la probabilidad de un suceso si se puede repetir muchas veces la experiencia: la probabilidad del suceso sería el valor al que tendería la frecuencia relativa del suceso. Podéis consultar más detalles acerca de esta aproximación.\nEn este caso, la cuestión estriba en poder hacer muchas veces la experiencia en condiciones independientes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "01-probabilidad.html#propiedades-inmediatas-de-la-probabilidad",
    "href": "01-probabilidad.html#propiedades-inmediatas-de-la-probabilidad",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "1.4 Propiedades inmediatas de la probabilidad",
    "text": "1.4 Propiedades inmediatas de la probabilidad\nVeremos a continuación una serie de propiedades que se deducen de manera inmediata de la axiomática de la probabilidad.\n\n1.4.1 Succeso nulo\nProbabilidad del suceso conjunto vacío (es decir del suceso que no contiene ningún resultado):\n\\[\nP(\\varnothing)=0\n\\]\n\n\n1.4.2 Suceso implicado\nSi A es un suceso que está contenido en B (todos los resultados de A también pertenecen a B ), entonces:\n\\[\n\\mathrm{P}(\\mathrm{A}) \\leq \\mathrm{P}(\\mathrm{B})\n\\]\n\n\n1.4.3 Complementario de un suceso\nSea \\(A^{\\mathrm{c}}\\) el suceso formado por todos los elementos de \\(\\Omega\\) que no pertenecen a A (Suceso complementario de A). La probabilidad de dicho suceso es igual a:\n\\[\n\\mathrm{P}\\left(\\mathrm{A}^{\\mathrm{c}}\\right)=1-\\mathrm{P}(\\mathrm{A})\n\\]\n\n\n1.4.4 Ocurrencia de algun suceso\nLa probabilidad de la unión de dos sucesos A y B es igual a:\n\\[\nP(A \\cup B)=P(A)+P(B)-P(A \\cap B)\n\\]\n\n\n1.4.5 Propiedad de que ocurra algun suceso\nSi tenemos una colección de \\(k\\) sucesos, la probabilidad de la unión de dichos sucesos será:\n\\[\nP\\left(\\bigcup_{i=1}^{k} A_{i}\\right)=\\sum_{i=1}^{k} P\\left(A_{i}\\right)-\\sum_{i&lt;j} P\\left(A_{i} \\cap A_{j}\\right)+\\sum P\\left(A_{i} \\cap A_{j} \\cap A_{k}\\right)+\\ldots+(-1)^{k+1} \\cdot P\\left(A_{1} \\cap . . \\cap A_{k}\\right)\n\\]\n\n\n1.4.6 Probabilidad de que ocurran dos (o más) sucesos a la vez\n\n\n1.4.7 Una formula que los relaciona\nSe verifica que:\n\\[\nP\\left(\\bigcap_{i=1}^{n} A_{i}\\right) \\geq 1-\\sum_{i=1}^{n} P\\left(\\bar{A}_{i}\\right)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "01-probabilidad.html#probabilidad-condicionada",
    "href": "01-probabilidad.html#probabilidad-condicionada",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "1.5 Probabilidad condicionada",
    "text": "1.5 Probabilidad condicionada\nImaginemos que en la experiencia de tirar un dado regular supiéramos de antemano que se ha obtenido un número par. Es decir, que se ha verificado el suceso: B = número par.\nPregunta: ¿Cuál es ahora la probabilidad de que se verifique el suceso mayor o igual a cuatro? Lógicamente, el resultado sería : \\(2 / 3\\). Por lo tanto, la probabilidad del suceso \\(\\mathrm{A}=\\) mayor o igual a cuatro se ha modificado. Evidentemente, ha pasado de ser \\(1 / 2\\) ( cuando no tenemos ninguna información previa) a ser \\(2 / 3\\) (cuando sabemos que se ha verificado el suceso B). ¿Cómo podemos anotar esta última probabilidad \\((2 / 3)\\) ? Muy sencillo. Anotaremos \\(\\mathrm{P}(\\mathrm{A} / \\mathrm{B})\\), que se lee como probabilidad de A condicionada a B . Así, en este ejemplo,\n\\[\n\\begin{gathered}\n\\mathrm{P}(\\mathrm{A} / \\mathrm{B})=2 / 3 \\\\\n\\mathrm{P}(\\mathrm{A})=1 / 2\n\\end{gathered}\n\\]\nEn términos generales, estamos en condiciones de poder definir la probabilidad condicionada, y lo hacemos como:\n\\[\nP(A / B)=\\frac{P(A \\cap B)}{P(B)}\n\\]\nPodemos ahora visualizar de una manera práctica y divertida el ejemplo anterior. Siguiendo con la notación utilizada, el suceso A será lo que denominamos suceso de obtención, mientras que el suceso B será lo que denominamos suceso condicionado. La pantalla nos proporcionará los casos posibles para el condicionante elegido y los casos favorables, calculando mediante la regla de Laplace la probabilidad del suceso.\n\nElegid suceso a estudiar. Desplazad, si procede, las barras de puntos.\nElegir suceso condicionante. Desplazad, si procede, las barras de puntos.\nComprobad los sucesos posibles y los favorables.\n\nLa probabilidad condicionada se comporta, entonces, como una función de probabilidad. Es decir, verifica los tres axiomas siguientes:\nAxioma 1:\n\\[\n\\mathrm{P}(\\mathrm{A} / \\mathrm{B}) \\geq 0\n\\]\nAxioma 2:\n\\[\nP(\\Omega / B)=1\n\\]\nAxioma 3:\n\\[\nP\\left(\\bigcup_{i=1}^{\\infty} A_{i} / B\\right)=\\sum_{i=1}^{\\infty} P\\left(A_{i} / B\\right)\n\\]\npara sucesos \\(\\mathrm{A}_{\\mathrm{i}}\\) con intersección vacía dos a dos.\n\n1.5.1 Sucesos dependientes y sucesos independientes\nSean A y B dos sucesos con probabilidad mayor que 0 . Evidentemente, si\n\\[\n\\mathrm{P}(\\mathrm{A} / \\mathrm{B})=\\mathrm{P}(\\mathrm{A})\n\\]\nB no ha modificado la probabilidad de que suceda A. En este caso diremos que son sucesos independientes.\nEn caso contrario diremos que son sucesos dependientes. En el ejemplo del apartado anterior, se observa que los sucesos son dependientes puesto que las probabilidades anteriores no coinciden.\nSe verifica que independencia de los sucesos A y B es equivalente a decir que la probabilidad de la intersección es igual a producto de probabilidades de los dos sucesos.\nSe verifica también que si A y B son independientes: a) El complementario del suceso A y el suceso B son independientes. b) El complementario del suceso A y el complementario del suceso B son independientes. c) El complementario del suceso B y el suceso A son independientes.\n\n\n1.5.2 Incompatibilidad e independencia\nDos sucesos con intersección vacía se denominan sucesos incompatibles. Esto, ¿qué implica? Pues, que si se verifica uno seguro que no se verifica el otro, ya que no tienen resultados en común. Por lo tanto es el caso extremo de dependencia. Obtenemos en este caso que:\n\\[\n\\mathrm{P}(\\mathrm{A} / \\mathrm{B})=0\n\\]\ny, en consecuencia, si \\(\\mathrm{P}(\\mathrm{A})\\) y \\(\\mathrm{P}(\\mathrm{B})\\) son diferentes de cero, la probabilidad condicionada anterior es diferente de \\(\\mathrm{P}(\\mathrm{A})\\), y así se deduce la dependencia.\nLa única posibilidad de que se dé incompatibilidad e independencia a la vez, es que alguno de los dos sucesos tenga probabilidad igual a cero.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "01-probabilidad.html#dos-teoremas-importantes",
    "href": "01-probabilidad.html#dos-teoremas-importantes",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "1.6 Dos Teoremas importantes",
    "text": "1.6 Dos Teoremas importantes\n\n1.6.1 Teorema de las probabilidades totales\nSea \\(\\Omega\\) el conjunto total formado por una partición (colección de sucesos con intersección vacía dos a dos):\n\\[\n\\Omega=H_{1} \\cup \\ldots \\ldots \\cup H_{n}\n\\]\nLa probabilidad de cualquier otro suceso A , se puede obtener a partir de las probabilidades de los sucesos de la partición y de las probabilidades de A condicionado a los sucesos de la partición, de la manera siguiente:\n\\[\nP(A)=\\sum_{i=1}^{n} P\\left(A / H_{i}\\right) \\cdot P\\left(H_{i}\\right)\n\\]\nEsto es lo que se conoce como teorema de las probabilidades totales.\n\n\n1.6.2 Teorema de Bayes\nEs una consecuencia del teorema de las probabilidades totales. Sea \\(\\Omega\\) el conjunto total formado por una partición (colección de sucesos con intersección vacía dos a dos).\n\\[\n\\Omega=H_{1} \\cup \\ldots \\ldots \\cup H_{n}\n\\]\nAhora el interés se centrará en la obtención de la probabilidad de cualquier suceso de la partición condicionada a un suceso A cualquiera.\nEl resultado será:\n\\[\nP\\left(\\mathrm{H}_{\\mathrm{i}} / \\mathrm{A}\\right)=\\frac{\\mathrm{P}\\left(\\mathrm{A} / \\mathrm{H}_{\\mathrm{i}}\\right) \\cdot \\mathrm{P}\\left(\\mathrm{H}_{\\mathrm{i}}\\right)}{\\sum_{i=1}^{n} \\mathrm{P}\\left(\\mathrm{A} / \\mathrm{H}_{\\mathrm{i}}\\right) \\cdot \\mathrm{P}\\left(\\mathrm{H}_{\\mathrm{i}}\\right)}\n\\]\nEsto es conocido como teorema o regla de Bayes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "01-probabilidad.html#introducción-a-los-experimentos-múltiples",
    "href": "01-probabilidad.html#introducción-a-los-experimentos-múltiples",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "1.7 Introducción a los experimentos múltiples",
    "text": "1.7 Introducción a los experimentos múltiples\nSupongamos que tiramos a la vez un dado y una moneda. Tenemos una experiencia múltiple, puesto que la experiencia que se realiza es la composición de dos experiencias (experiencia \\(1=\\) tirar un dado regular; experiencia 2 = tirar una moneda regular). ¿Cuál es en este caso el conjunto de resultados? Si \\(\\Omega_{1}\\) es el conjunto de resultados asociado con la experiencia tirar un dado y \\(\\Omega_{2}\\) es el conjunto de resultados asociado con la experiencia tirar una moneda, el conjunto de resultados asociado a la experiencia múltiple será \\(\\Omega_{1} \\times \\Omega_{2}\\).\nEs decir, \\(\\Omega_{1}=\\{1,2,3,4,5,6\\}\\) \\(\\Omega_{2}=\\{\\) cara, cruz \\(\\}\\) \\(\\Omega_{1} \\times \\Omega_{2}=\\{(1\\), cara \\(),(2\\), cara \\(),(3\\), cara \\(),(4\\), cara \\(),(5\\), cara \\(),(6\\), cara \\(),(1\\), cruz ), ( 2 , cruz ), ( 3, cruz ), (4, cruz \\(),(5\\), cruz \\(),(6\\), cruz \\()\\}\\)\nSi \\(\\mathrm{P}_{1}\\) y \\(\\mathrm{P}_{2}\\) son, respectivamente, las funciones de probabilidad asociadas a las experiencias 1 y 2 , ¿es posible calcular probabilidades de la experiencia múltiple a partir de \\(\\mathrm{P}_{1}\\) y \\(\\mathrm{P}_{2}\\) ?\nEfectivamente! Pero hemos de distinguir dos situaciones:\n\nExperiencias independientes: cuando el resultado de una no influya en la otra.\nExperiencias dependientes: cuando el resultado de una influya en la otra.\n\nEn nuestro caso se trata de experiencias independientes, puesto que el resultado que se obtenga al tirar el dado no influye sobre el resultado que se obtenga al lanzar la moneda y al revés. ¿Como se calculan, pues, las probabilidades de la experiencia múltiple? Sea un suceso de la experiencia múltiple: A x B.\n\nCaso de experiencias independientes:\n\n\\[\n\\mathrm{P}(\\mathrm{A} \\times \\mathrm{B})=\\mathrm{P}_{1}(\\mathrm{~A}) \\times \\mathrm{P}_{2}(\\mathrm{~B})\n\\]\n\nCaso de experiencias dependientes:\n\n\\[\n\\mathrm{P}(\\mathrm{A} \\times \\mathrm{B})=\\mathrm{P}_{1}(\\mathrm{~A}) \\times \\mathrm{P}_{2}(\\mathrm{~B} / \\mathrm{A})\n\\]\nEntendemos que existe una \\(\\mathrm{P}_{2}\\) para cada suceso A .\nEsto que hemos explicado se puede, lógicamente, generalizar a una experiencia múltiple formada por \\(n\\) experiencias.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "01-probabilidad.html#combinatoria",
    "href": "01-probabilidad.html#combinatoria",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "1.8 Combinatoria",
    "text": "1.8 Combinatoria\nVeamos algunas fórmulas simples que se utilizan en combinatoria y que nos pueden ayudar a calcular el número de casos posibles o el número de casos favorables.\n\n1.8.1 Permutaciones\nSea un conjunto de \\(n\\) elementos. A las ordenaciones que se pueden hacer con estos \\(n\\) elementos \\(\\sin\\) repetir ningún elemento y utilizándolos todos se las denomina permutaciones. El número de permutaciones que se pueden realizar coincide con el factorial de \\(n\\), y su cálculo es:\n\\[\nn!=n \\cdot(n-1) \\cdot(n-2) \\ldots \\ldots .2 \\cdot 1\n\\]\nEjemplo:\n¿De cuántas maneras distintas podemos alinear a seis personas en una fila?\nRespuesta\nDe \\(6!=6 \\cdot 5 \\cdot 4 \\cdot 3 \\cdot 2 \\cdot 1=720\\) maneras (permutaciones de 6 elementos).\n\n\n1.8.2 Variaciones\nSea un conjunto de \\(n\\) elementos. Supongamos que deseamos ordenar \\(r\\) elementos de entre los \\(n\\). A cada una de estas ordenaciones la denominamos variación. El número de variaciones que se pueden hacer de los \\(n\\) elementos tomados de \\(r\\) en \\(r\\) es:\n\\[\nV_{n}^{r}=n \\cdot(n-1) \\ldots \\ldots(n-r+1)\n\\]\nEjemplo\nEn una carrera de velocidad compiten diez atletas. ¿De cuántas maneras distintas podría estar formado el podio? (el podio lo forman el primer, el segundo y el tercer clasificado)\nRespuesta\nCada podio posible es una variación de diez elementos tomado de tres en tres. Por tanto, el número posible de podios es:\n\\[\n\\mathrm{V}_{10}^{3}=10.9 .8=720\n\\]\n\n\n1.8.3 Variaciones con repetición\nSea un conjunto de \\(n\\) elementos. Supongamos que se trata de ordenar \\(r\\) elementos que pueden estar repetidos. Cada ordenación es una variación con repetición. El número de variaciones con repetición para un conjunto de \\(n\\) tomados de \\(r\\) en \\(r\\) es :\n\\[\n\\mathrm{RV}_{\\mathrm{n}}^{\\mathrm{r}}=\\mathrm{n}^{\\mathrm{r}}\n\\]\nEjemplo\nEn una urna tenemos cinco bolas numeradas del 1 al 5 . Se extraen tres bolas sucesivamente con reposición (devolviendo cada vez la bola a la urna). ¿Cuántos resultados distintos es posible obtener?\nRespuesta: Se trata de variaciones con repetición de un conjunto de cinco bolas tomadas de tres en tres. En total tendremos:\n\\[\n\\mathrm{RV}_{5}^{3}=5^{3}=125\n\\]\n\n\n1.8.4 Combinaciones\nCuando se trata de contar el número de subconjuntos de \\(x\\) elementos en un conjunto de \\(n\\) elementos tenemos lo que se denomina combinaciones de x elementos en un conjunto de n . El cálculo del contaje se hace mediante el número combinatorio, de la manera siguiente:\n\\[\n\\mathrm{C}_{\\mathrm{n}}^{\\mathrm{x}}=\\binom{n}{\\mathrm{x}}=\\frac{\\mathrm{n!}}{\\mathrm{x}!.(\\mathrm{n}-\\mathrm{x})!}\n\\]\nEjemplo\n¿De cuántas maneras podemos elegir, en la urna anterior (recordemos que había cinco bolas), tres bolas en una única extracción?\nRespuesta\nSerán combinaciones de cinco elementos tomados de tres en tres, por tanto, tendremos:\n\\[\n\\mathrm{C}_{5}^{3}=\\binom{5}{3}=\\frac{5!}{3!(5-3)!}=10\n\\]\n\n\n1.8.5 Permutaciones con repetición\nSea un conjunto de \\(n\\) elementos, de entre los cuales tenemos \\(a\\) elementos indistinguibles entre sí, \\(b\\) elementos indistinguibles entre sí, \\(c\\) elementos indistinguibles entre sí, etc. Cada ordenación de estos elementos se denominará permutación con repetición. El número de permutaciones con repetición es:\n\\[\nR P{ }_{n}^{a, b, c, \\ldots}=\\frac{n!}{a!b!c!\\ldots}\n\\]\nEjemplo\n¿Cuantas palabras con sentido o sin él pueden formarse con las letras PATATA?\nRespuesta: Tenemos tres veces la letra A, dos veces la T y una vez la P. Por tanto, serán:\n\\[\n\\mathrm{RP}_{6}^{3,2,1}=\\frac{6!}{3!2!!}=60\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "01-probabilidad.html#frecuencia-relativa-y-probabilidad",
    "href": "01-probabilidad.html#frecuencia-relativa-y-probabilidad",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "1.9 Frecuencia relativa y probabilidad",
    "text": "1.9 Frecuencia relativa y probabilidad\nLa definición moderna de probabilidad basada en la axiomática de Kolmogorov (presentada anteriormente) es relativamente reciente. Históricamente hubo otros intentos previos de definir el escurridizo concepto de probabilidad, descartados por diferentes razones. Sin embargo conviene destacar aquí algunas ideas que aparecen en la antigua definición basada en la frecuencia relativa, ya que permiten intuir algunas profundas propiedades de la probabilidad.\nRecordemos antes que si en un experimento que se ha repetido \\(n\\) veces un determinado suceso A se ha observado en \\(k\\) de estas repeticiones, la frecuencia relativa \\(\\mathrm{f}_{\\mathrm{r}}\\) del suceso A es:\n\\[\n\\mathrm{f}_{\\mathrm{r}}=k / n\n\\]\nEl interés por la frecuencia relativa y su relación con el concepto de probabilidad aparece a lo largo de los siglos XVIII a XX al observar el comportamiento de numerosas repeticiones de experimentos reales.\nA título de ejemplo de un experimento de este tipo, supongamos que se dispone de una moneda ideal perfectamente equilibrada. Aplicando directamente la regla de Laplace resulta claro que el suceso \\(\\mathrm{A}=\\) obtener cara tiene probabilidad:\n\\[\n\\mathrm{p}(\\mathrm{A})=1 / 2=0,5\n\\] ### Ilustración por simulación\nEn el enlace siguiente se accede a una simulación por ordenador de la ley de los grandes números en la que se basa precisamente la idea de asimilar “a la larga” (es decir a medida que crece el número de repeticiones) frecuencia relativa y probabilidad.\n\nEnlace a la simulación\n\nEn la simulación podéis definir:\n\nLa verdadera probabilidad” de que al tirar la moneda salga cara,\nEL número de tiradas.\n\nComo podréis comprobar, sea cual sea la probabilidad (una moneda justa es un 0.5) a la larga la frecuencia relativa converge hacia el valor que habéis fijado.\nEso sí, observad lo que sucede si fijais probabilidades cercanas a 0.5 o muy alejadas de ell.\n¿La idea de lo que sucede a la larga es la misma? ¿En que encontráis diferencias? Aunque no deje de llamar la atención el carácter errático del comportamiento de \\(\\mathrm{f}_{\\mathrm{r}}\\) entre los valores 0 y 1, estaréis seguramente de acuerdo que a mayor número de lanzamientos \\(n\\), más improbable es que \\(f_{r}\\) se aleje mucho de \\(p(A)\\).\nLa teoría moderna de la probabilidad enlaza formalmente estas ideas con el estudio de las leyes de los grandes números, que se discutiran con más detalle en el capítulo dedicado a las “Grandes muestras”.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "01-probabilidad.html#caso-de-estudio-eficacia-de-una-prueba-diagnóstica",
    "href": "01-probabilidad.html#caso-de-estudio-eficacia-de-una-prueba-diagnóstica",
    "title": "1  Probabilidad y Experimentos aleatorios",
    "section": "1.10 CASO DE ESTUDIO: Eficacia de una prueba diagnóstica",
    "text": "1.10 CASO DE ESTUDIO: Eficacia de una prueba diagnóstica\nPara decidir la presencia(E) o ausencia (A) de sordera profunda a la edad de seis meses, se está ensayando una batería de tests.\nConsiderando el caso en que la prueba pueda dar positivo \\((+)\\) o negativo \\((-)\\), hay que tener en cuenta que en individuos con dicha sordera la prueba dará a veces positivo y a veces negativo, e igual ocurrirá con individuos que no presentan la sordera.\nEn este contexto todas las probabilidades pueden ser interpretadas en terminos de resultados positivos o neghativos, correctamente o no y cada una ha recibe un nombre que la ha popularizado dentro de la literatura médica:\nAsí tenemos:\n\n\\(\\mathrm{P}(+/ \\mathrm{E})\\)\n\nProbabilidad de test positivo en individuos que padecen la sordera.\nEste valor se conoce como sensibilidad del test.\n\n\\(\\mathrm{P}(+/ \\mathrm{A})=\\)\n\nProbabilidad de test positivo en individuos que no padecen la sordera.\nEste valor se conoce como probabilidad de falso-positivo.\n\n\\(\\mathrm{P}(-/ \\mathrm{E})=\\)\n\nProbabilidad de test negativo en individuos que padecen la sordera\nEste valor se conoce como probabilidad de falso-negativo.\n\n\\(P(-/ A)=\\)\n\nProbabilidad de test negativo en individuos que no padecen sordera.\nEste valor se conoce como especificidad del test.\n\nFinalmente a la probabilidad, \\(\\mathrm{P}(\\mathrm{E})\\), de presentar la enfermedad se le conoce como prevalencia de la enfermedad.\n\nLógicamente, en un “buen test” nos interesa que la sensibilidad y la especificidad sean elevadas, mientras que los falsos-positivos y falsos-negativos sean valores bajos.\nAdemás no debemos olvidar que, el interés de aplicar el test, consiste en que sirva de elemento predictivo para diagnosticar la sordera.\nPor lo tanto, interesa que las probabilidades:\n\n\\(\\mathrm{P}(\\mathrm{E} /+)=\\) Probabilidad de padecer sordera si el test da positivo\n\\(\\mathrm{P}(\\mathrm{A} /-)=\\) Probabilidad de no padecer sordera si el test da negativo\n\nsean realmente altas.\nA las probabilidades anteriores se las conoce como: valores predictivos del test, en concreto:\n\n\\(\\mathrm{P}(\\mathrm{E} /+)=\\) es el valor predictivo positivo y\n\\(\\mathrm{P}(\\mathrm{A} /-)=\\) es el valor predictivo negativo\n\n\n1.10.1 Aplicación del Teorema de Bayes\nEstamos en una situación en que, a partir de conocimiento de unas probabilidades, nos interesa calcular otras, para lo que utilizaremos el teorema de Bayes.\nHabitualmente, a partir de estudios epidemiológicos y muestras experimentales, se estiman:\n\nLa prevalencia\nLa sensibilidad del test\nLa especificidad del test\nLa probabilidad de falso positivo\nLa probabilidad de falso negativo\n\n¿Cómo se obtiene entonces el valor predictivo del test?\nVeamos como aplicar el teorema de Bayes a este problema:\nSi dividimos a la población global (en este caso, el conjunto de todos los bebés de seis meses) entre los que padecen sordera y los que no la padecen, aplicando el teorema de Bayes resulta que:\n\\[\n\\mathrm{P}(\\mathrm{E} /+)=(\\mathrm{P}(+/ \\mathrm{E}) \\times \\mathrm{P}(\\mathrm{E})) /(\\mathrm{P}(+/ \\mathrm{E}) \\times \\mathrm{P}(\\mathrm{E})+\\mathrm{P}(+/ \\mathrm{A}) \\times \\mathrm{P}(\\mathrm{~A}))\n\\] y\n\\[\n\\mathrm{P}(\\mathrm{~A} /-)=(\\mathrm{P}(-/ \\mathrm{A}) \\times \\mathrm{P}(\\mathrm{~A})) /(\\mathrm{P}(-/ \\mathrm{A}) \\times \\mathrm{P}(\\mathrm{~A})+\\mathrm{P}(-/ \\mathrm{E}) \\times \\mathrm{P}(\\mathrm{E}))\n\\]\n\n\n1.10.2 Ejemplo numérico\nSupongamos que en el ejemplo de la sordera, se sabe que:\n\nPrevalencia \\(=0,003\\), Es decir, que un tres por mil padece sordera profunda a esta edad.\nSensibilidad \\(=0,98\\)\nEspecificidad \\(=0,95\\)\nProbabilidad de falso positivo \\(=0,05\\)\nProbabilidad de falso negativo \\(=0,02\\)\n\n¿Cuál es el valor predictivo del test?\n\\[\n\\begin{aligned}\n& \\mathrm{P}(\\mathrm{E} /+)=(0,98 \\times 0,003) /(0,98 \\times 0,003+0,05 \\times 0,997)=0,00294 / 0,05279=0,055692 \\\\\n& \\mathrm{P}(\\mathrm{~A} /-)=(0,95 \\times 0,997) /(0,95 \\times 0,997+0,02 \\times 0,003)=0,94715 / 0,94721=0,999936\n\\end{aligned}\n\\]\nEn conclusión, Podemos afirmar que se trata de un test muy válido para decidir que no hay sordera en caso de que el resultado del test sea negativo.\nSin embargo, el valor tan bajo de \\(\\mathrm{P}(\\mathrm{E} /+)\\) no permite poder considerar al test como un predictor válido para diagnosticar la sordera.\nObsérvese que:\n\nProbabilidad de falso positivo \\(=1-\\) especificidad\nProbabilidad de falso negativo \\(=1-\\) sensibilidad",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Probabilidad y Experimentos aleatorios</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html",
    "href": "02-variablesAleatorias.html",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "",
    "text": "2.1 El espacio muestral y sus elementos\nCuando llevamos a cabo un experimento aleatorio, el conjunto \\(\\Omega\\) de resultados posibles forman el denominado espacio muestral. Sus elementos \\(\\omega\\) (resultados o sucesos elementales) deben ser conocidos por el investigador que realiza la experiencia, aun cuando no podamos determinar a priori el resultado particular de una realización concreta.\nSupondremos que también conocemos la manera de asignar una probabilidad sobre el conjunto de enunciados o sucesos observables que se pueden construir a partir de \\(\\Omega\\). Es decir, supondremos la existencia de un espacio de probabilidad construido a partir de los resultados de \\(\\Omega\\).\nGeneralmente, la estructura del espacio muestral no permite, o por lo menos no facilita, su tratamiento matemático. Pensemos en la inmensa variedad en la naturaleza de resultados posibles de diferentes experimentos. Además es bastante frecuente que no nos interesen los resultados en sí, sino una característica que, de alguna manera, resuma el resultado del experimento.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#representación-numérica-de-los-sucesos-elementales.-variables-aleatorias",
    "href": "02-variablesAleatorias.html#representación-numérica-de-los-sucesos-elementales.-variables-aleatorias",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.2 Representación numérica de los sucesos elementales. Variables aleatorias",
    "text": "2.2 Representación numérica de los sucesos elementales. Variables aleatorias\nLa forma de resumen que adoptaremos es la asignación a cada suceso elemental de un valor numérico, en particular, de un número real.\nEn la práctica la asignación de un valor numérico a cada elemento del espacio muestral se hace siguiendo una regla o enunciado, según el interés concreto del experimentador. Evidentemente, podemos construir diversas maneras de asignar valores numéricos a los mismos resultados de un experimento.\nHablando en términos coloquiales, podemos decir que cada regla de asignación corresponde a una determinada variable que se puede medir sobre los sucesos elementales.\nNótese que es posible construir múltiples variables sobre un mismo espacio de probabilidad. En términos algo más formales, las reglas de asignación se pueden interpretar como una aplicación de \\(\\Omega\\) en el conjunto de números reales. \\[\n\\begin{aligned}\nX: \\Omega & \\rightarrow \\mathbb{R} \\\\\n\\omega & \\rightarrow X(\\omega)\n\\end{aligned}\n\\]\n\\(X\\) representa la variable o regla de asignación concreta. El conjunto de valores numéricos que puede tomar una variable, y que depende de la naturaleza de la misma variable, recibe el nombre de recorrido de la variable.\nA partir de este momento, los sucesos elementales quedan substituidos por sus valores numéricos de acuerdo a una determinada variable y permiten un mayor tratamiento matemático en el marco de la teoría de la probabilidad.\nEl apelativo aleatoria que reciben las variables hace referencia al hecho de que los posibles valores que toman dependen de los resultados de un fenómeno aleatorio que se presentan con una determinada probabilidad.\nComo un complemento al tema presentamos la definición formal de variable aleatoria, donde se introducen las restricciones a las reglas de asignación numérica que posibilitan el tratamiento matemático de las variables.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#caracterización-de-una-variable-aleatoria-a-través-de-la-probabilidad.-función-de-distribución",
    "href": "02-variablesAleatorias.html#caracterización-de-una-variable-aleatoria-a-través-de-la-probabilidad.-función-de-distribución",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.3 Caracterización de una variable aleatoria a través de la probabilidad. Función de distribución",
    "text": "2.3 Caracterización de una variable aleatoria a través de la probabilidad. Función de distribución\nUna vez que tenemos definida una variable aleatoria, ésta queda totalmente caracterizada en el momento en que somos capaces de determinar la probabilidad de que la variable tome valores en cualquier intervalo de la recta real. Dado que los posibles valores que puede tomar la variable, es decir, su recorrido, pueden ser muy grandes (infinitos de hecho), el problema de caracterizar una variable aleatoria se ha resuelto a través de la definición de una serie de funciones matemáticas.\nLa más general de dichas funciones es la función de distribución. Definimos la función de distribución de una variable aleatoria \\(X\\) como la aplicación\n\\[\n\\begin{array}{rll}\nF: & \\mathbb{R} & \\rightarrow[0,1] \\\\\n& x & \\rightarrow F(x)=P(X \\leq x)=P\\{\\omega \\in \\Omega \\mid X(\\omega) \\leq x\\}\n\\end{array}\n\\]\nPor tanto, para cada punto de la recta real, el valor de la función de distribución es la probabilidad del suceso formado por los resultados del experimento que tienen asignado un valor de la variable aleatoria menor o igual a dicho punto. O también podemos decir que es la probabilidad inducida en el intervalo de la recta \\((-\\infty, x]\\).\nHay que hacer notar que siempre será posible determinar dicha probabilidad gracias a los requerimientos exigidos en la definición formal de variable aleatoria. Por tanto, toda variable aleatoria tiene asociada una función de distribución. Nos referimos a esta función cuando decimos que conocemos la distribución de la variable aleatoria.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#propiedades-de-la-función-de-distribución",
    "href": "02-variablesAleatorias.html#propiedades-de-la-función-de-distribución",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.4 Propiedades de la función de distribución",
    "text": "2.4 Propiedades de la función de distribución\nResumimos a continuación las propiedades más importantes de la función de distribución:\n\n\\(0 \\leq F(x) \\leq 1\\)\n\\(\\lim _{x \\rightarrow+\\infty} F(x)=1\\)\n\\(\\lim _{x \\rightarrow-\\infty} F(x)=0\\)\n\\(x_{1}&lt;x_{2} \\Rightarrow F\\left(x_{1}\\right) \\leq F\\left(x_{2}\\right)\\)\n\\(\\lim _{x \\rightarrow a^{+}} F(x)=F(a) \\quad \\forall a \\in \\mathbb{R}_{\\text {la derecha. }}^{\\text {Función siempre continua por }}\\)\n\nToda función que verifique las propiedades anteriores es una función de distribución y toda función de distribución caracteriza una determinada variable aleatoria sobre algún espacio de probabilidad.\nLas propiedades anteriores se traducen en un tipo de gráfica para la función de distribución del tipo de las que mostramos a continuación:\nPrimer tipo\n\nSegundo tipo\n\nEvidentemente, podrían aparecer distribuciones, y por tanto gráficas, que combinen las características de los dos modelos anteriores.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#clasificación-de-las-variables-aleatorias",
    "href": "02-variablesAleatorias.html#clasificación-de-las-variables-aleatorias",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.5 Clasificación de las variables aleatorias",
    "text": "2.5 Clasificación de las variables aleatorias\nPara su estudio, las variables aleatorias se clasifican en variables discretas o variables contínuas.\n\n2.5.1 Variables aleatorias discretas\nDiremos que una variable aleatoria es discreta si su recorrido es finito o infinito numerable. Generalmente, este tipo de variables van asociadas a experimentos en los cuales se cuenta el número de veces que se ha presentado un suceso o donde el resultado es una puntuación concreta.\nLos puntos del recorrido se corresponden con saltos en la gráfica de la función de distribución, que correspondería al segundo tipo de gráfica visto anteriormente.\n\n\n2.5.2 Variables aleatorias continuas\nSon aquellas en las que la función de distribución es una función continua. Se corresponde con el primer tipo de gráfica visto.\nGeneralmente, se corresponden con variables asociadas a experimentos en los cuales la variable medida puede tomar cualquier valor en un intervalo; mediciones biométricas, por ejemplo.\nUn caso particular dentro de las variables aleatorias continuas y al cual pertenecen todos los ejemplos usualmente utilizados, son las denominadas variables aleatorias absolutamente continuas.\n\n2.5.2.1 Variables aleatorias absolutamente continuas\nDiremos que una variable aleatoria \\(X\\) continua tiene una distribución absolutamente continua si existe una función real \\(f\\), positiva e integrable en el conjunto de números reales, tal que la función de distribución \\(F\\) de \\(X\\) se puede expresar como\n\\[\nF(x)=\\int_{-\\infty}^{x} f(t) d t\n\\]\nUna variable aleatoria con distribución absolutamente continua, por extensión, se la clasifica como variable aleatoria absolutamente continua.\nA la función \\(f\\) se la denomina función de densidad de probabilidad de la variable \\(X\\).\nHay que hacer notar que no toda variable continua es absolutamente continua, pero los ejemplos son complicados, algunos utilizan para su construcción el conjunto de Cantor, y quedan fuera del nivel y del objetivo de este curso.\nIgualmente indicaremos que los tipos de variables comentados anteriormente forman únicamente una parte de todos los posibles tipos de variables, sin embargo contienen prácticamente todas las variables aleatorias que encontramos usualmente.\nTal como se estudiará más adelante, existen algunas familias de funciones de distribución, tanto dentro del grupo de las discretas como de las continuas, que por su importancia reciben un nombre propio y se estudiarán en los capítulos siguientes.\nEn ocasiones encontramos variables de tipo mixto, es decir que se comportan como discretas o contínuas para distintos grupos de valores.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#variable-aleatoria-discretas",
    "href": "02-variablesAleatorias.html#variable-aleatoria-discretas",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.6 Variable aleatoria discretas",
    "text": "2.6 Variable aleatoria discretas\nUna variable aleatoria \\(X\\) diremos que es discreta si su recorrido es finito o infinito numerable, recorrido que denotaremos de la forma \\(\\left\\{x_{1}, x_{2}, \\ldots, x_{\\mathrm{k}}, \\ldots\\right\\}\\).\nEl ejemplo más sencillo de variable aleatoria discreta lo constituyen las variables indicadoras. Sea \\(A\\) un suceso observable, se llama indicador de \\(A\\) a la variable aleatoria definida por\n\\[\n\\begin{aligned}\nI_{A}: \\Omega & \\rightarrow \\mathbb{R} \\\\\n\\omega & \\rightarrow I_{A}(\\omega)=\\left\\{\\begin{array}{lll}\n1 & \\text { si } \\omega \\in A \\\\\n0 & \\text { si } & A\n\\end{array}\\right.\n\\end{aligned}\n\\]\n\n2.6.0.1 Ejercicio:\nConstruir, a partir de las variables indicadoras de \\(A\\) y \\(B\\), las siguientes variables indicadoras?\n\\[\nI_{A \\cap B} ; I_{A \\cup B} ; I_{A} c ; I_{\\Omega}\n\\]\n\n2.6.0.1.1 Solución\n\\[\n\\begin{gathered}\nI_{A \\cap B}=I_{A} \\cdot I_{B} \\\\\nI_{A \\cup B}=I_{A}+I_{B}-I_{A \\cap B} \\\\\nI_{A} c=1-I_{A} \\\\\n\\Omega=1\n\\end{gathered}\n\\]\n\n\n\n2.6.1 Caracterización a través de la función de densidad o de probabilidad\nLas variables aleatorias discretas vienen caracterizadas a través de una función que asocia cada elemento del recorrido con su probabilidad. Dicha función recibe varios nombres según los autores: función o ley de probabilidad, o también función de densidad de la variable aleatoria discreta.\nPodemos representarla de la manera siguiente:\n\\[\n\\begin{array}{rll}\nf: & \\mathbb{R} & \\rightarrow[0,1] \\\\\n& x & \\rightarrow f(x)=P(X=x)=P\\{\\omega \\in \\Omega \\mid X(\\omega)=x\\}\n\\end{array}\n\\]\nLa función definida anteriormente es nula en todo punto que no pertenezca al recorrido. Es evidente que, al ser una probabilidad, la función de densidad discreta está acotada \\(0 \\leq f(x) \\leq 1\\). Toda función de densidad discreta puede expresarse de manera explícita a través de una tabla que asocie directamente puntos del recorrido con sus probabilidades.\nEjemplo: Consideremos la variable indicadora del suceso \\(A\\) :\n\\[\n\\begin{aligned}\nI_{A}: \\Omega & \\rightarrow \\mathbb{R} \\\\\n\\omega & \\rightarrow I_{A}(\\omega)=\\left\\{\\begin{array}{lll}\n1 & \\text { si } & \\omega \\in A \\\\\n0 & \\text { si } & A\n\\end{array}\\right.\n\\end{aligned}\n\\]\nLa función de densidad de esta variable sería la siguiente:\n\n\n\n\\(x\\)\n0\n1\n\n\n\n\n\\(f(x)=P(X=x)\\)\n\\(1-P(A)=P\\left(A^{\\mathrm{c}}\\right)\\)\n\\(P(A)\\)\n\n\n\nEl recorrido está formado por dos valores: 1 y 0 , con las mismas probabilidades que las del suceso \\(A\\) y su complementario, respectivamente.\nEn otros casos la función de densidad se expresa a través de una fórmula matemática que define una regla de asignación de probabilidades para los valores del recorrido.\n\n2.6.1.1 Ejemplo\n\\[\nP(X=x)=0,2 \\cdot 0,8^{x-1}, \\quad x=1,2, \\ldots\n\\]\nes la función de densidad de una variable aleatoria discreta con recorrido numerable.\n\n\n\n2.6.2 Propiedades de la función de densidad discreta\n\n\n\n\\[\n0 \\leq f(x) \\leq 1\n\\]\n\n\\(\\sum_{i=1}^{n} f\\left(x_{i}\\right)=1\\), si el recorrido es finito.\n\\(\\sum_{i=1}^{\\infty} f\\left(x_{i}\\right)=1\\), si el recorrido es numerable.\n\n\n\n2.6.3 Relaciones entre la función de distribución y la función de densidad discreta.  Probabilidad de intervalos.\nExiste una relación muy importante entre las funciones de distribución \\(F(x)\\) y de densidad \\(f(x)\\) de una variable aleatoria discreta. La función de distribución en un punto se obtiene acumulando el valor de la función de densidad para todos los valores del recorrido menores o iguales al punto en cuestión.\n\\[\nF(x)=\\sum_{x_{i} \\leq x} f\\left(x_{i}\\right) \\quad \\text { para todo } \\mathrm{x}_{\\mathrm{i}} \\text { perteneciente al recorrido de la variable. }\n\\]\nEn efecto, supongamos que el recorrido de una variable discreta \\(X\\) es \\(\\left\\{x_{1}, x_{2}, \\ldots, x_{k}, \\ldots\\right\\}\\) y que deseamos conocer el valor de la función de distribución en un punto \\(x\\) tal que \\(x_{i} \\leq x&lt;x_{i+1}\\), entonces es inmediato que\n\\[\nF(x)=P(X \\leq x)=P\\left(X=x_{1}\\right)+P\\left(X=x_{2}\\right)+\\ldots+P\\left(X=x_{i}\\right)=f\\left(x_{1}\\right)+f\\left(x_{2}\\right)+f\\left(x_{3}\\right)+\\ldots+f\\left(x_{i}\\right)\n\\]\nPor ejemplo, para una variable indicadora de un suceso \\(A\\), tenemos la relación siguiente:\n\n\n\n\n\n\n\n\nValor de \\(\\boldsymbol{x}\\)\n\\(\\boldsymbol{f}(\\boldsymbol{x})\\)\n\\(\\boldsymbol{F}(\\boldsymbol{x})\\)\n\n\n\n\n\\((-\\infty, 0)\\)\n\n0\n\n\n0\n\\(P\\left(A^{c}\\right)\\)\n\\(P\\left(A^{\\mathrm{c}}\\right)\\)\n\n\n\\((0,1)\\)\n\n\\(P\\left(A^{\\mathrm{c}}\\right)\\)\n\n\n1\n\\(P(A)\\)\n\\(P\\left(A^{\\mathrm{c}}\\right)+P(A)=1\\)\n\n\n\\((1,+\\infty)\\)\n\n1\n\n\n\nA partir de las funciones de densidad y de distribución es posible expresar las probabilidades para cualquier posible intervalo de valores de la variable. Por ejemplo:\n\n\n\nIntervalo\n\n\n\n\n\\(P(X \\leq a)=F(a)\\)\n\n\n\\(P(X&lt;a)=F(a)-f(a)\\)\n\n\n\\(P(X&gt;a)=1-F(a)=1-P(X \\leq a)\\)\n\n\n\\(P(X \\geq a)=1-F(a)+f(a)=1-P(X&gt;a)\\)\n\n\n\\(P(a&lt;X \\leq b)=F(b)-F(a)\\)\n\n\n\\(P(a&lt;X&lt;b)=F(b)-f(b)-F(a)\\)\n\n\n\\(P(a \\leq X \\leq b)=F(b)-F(a)+f(a)\\)\n\n\n\\(P(a \\leq X&lt;b)=F(b)-f(b)-F(a)+f(a)\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#variables-aleatorias-continuas-1",
    "href": "02-variablesAleatorias.html#variables-aleatorias-continuas-1",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.7 Variables aleatorias continuas",
    "text": "2.7 Variables aleatorias continuas\nUna variable aleatoria \\(X\\) diremos que es continua si su función de distribución es una función continua. En la práctica, se corresponden con variables asociadas con experimentos en los cuales la variable medida puede tomar cualquier valor en un intervalo: mediciones biométricas, intervalos de tiempo, áreas, etc.\n\n2.7.1 Ejemplos\n\nResultado de un generador de números aleatorios entre 0 y 1. Es el ejemplo más sencillo que podemos considerar, es un caso particular de una familia de variables aleatorias que tienen una distribución uniforme en un intervalo \\([a, b]\\). Se corresponde con la elección al azar de cualquier valor entre \\(a\\) y \\(b\\).\nEstatura de una persona elegida al azar en una población. El valor que se obtenga será una medición en cualquier unidad de longitud ( m , cm , etc.) dentro de unos límites condicionados por la naturaleza de la variable. El resultado es impredecible con antelación, pero existen intervalos de valores más probables que otros debido a la distribución de alturas en la población. Más adelante veremos que, generalmente, variables biométricas como la altura se adaptan un modelo de distribución denominado distribución Normal y representado por una campana de Gauss.\n\nDentro de las variables aleatorias continuas tenemos las variables aleatorias absolutamente continuas.\nDiremos que una variable aleatoria \\(X\\) continua tiene una distribución absolutamente continua si existe una función real \\(f\\), positiva e integrable en el conjunto de números reales, tal que la función de distribución \\(F\\) de \\(X\\) se puede expresar como\n\\[\nF(x)=\\int_{-\\infty}^{x} f(t) d t\n\\]\nUna variable aleatoria con distribución absolutamente continua, por extensión, se clasifica como variable aleatoria absolutamente continua.\nEn cuanto a nuestro manual, todas las variables aleatorias continuas con las que trabajemos pertenecen al grupo de las variables absolutamente continuas, en particular, los ejemplos y casos expuestos.\n\n\n2.7.2 Función de densidad continua\nLa función que caracteriza las variables continuas es aquella función \\(f\\) positiva e integrable en los reales, tal que acumulada desde \\(-\\infty\\) hasta un punto \\(x\\), nos proporciona el valor de la función de distribución en \\(x, F(\\mathrm{x})\\). Recibe el nombre de función de densidad de la variable aleatoria continua.\n\\[\nF(x)=\\int_{-\\infty}^{x} f(t) d t\n\\]\nLas funciones de densidad discreta y continua tienen, por tanto, un significado análogo, ambas son las funciones que acumuladas (en forma de sumatorio en el caso discreto o en forma de integral en el caso continuo) dan como resultado la función de distribución.\nLa diferencia entre ambas, sin embargo, es notable.\n\nLa función de densidad discreta toma valores positivos únicamente en los puntos del recorrido y se interpreta como la probabilidad de la que la variable tome ese valor \\(f(x)=P(X=x)\\).\nLa función de densidad continua toma valores en el conjunto de números reales y no se interpreta como una probabilidad. No está acotada por 1, puede tomar cualquier valor positivo. Es más, en una variable continua se cumple que probabilidades definidas sobre puntos concretos siempre son nulas.\n\n\\[\nP(X=x)=0 \\text { para todo } x \\text { real. }\n\\]\n¿Cómo se interpreta, entonces, la función de densidad continua? Las probabilidades son las áreas bajo la función de densidad. El área bajo la función de densidad entre dos puntos a y b se interpreta como la probabilidad de que la variable aleatoria tome valores comprendidos entre \\(a\\) y \\(b\\).\nPor tanto, siempre se cumple lo siguiente:\n\\[\n\\int_{-\\infty}^{+\\infty} f(x) d x=1\n\\]\nLa función de densidad se expresa a través de una función matemática. La forma específica de la función matemática generalmente pasa por considerar a la variable aleatoria como miembro de una determinada familia de distribuciones, un determinado modelo de probabilidad. Estas familias generalmente dependen de uno o más parámetros y serán objeto de un estudio específico en un capítulo posterior. La atribución a una determinada familia depende de la naturaleza de la variable en cuestión.\nPodemos ver, únicamente con ánimo ilustrativo, la expresión analítica y la gráfica para los ejemplos comentados con anterioridad:\n\nResultado de un generador de números aleatorios entre \\(\\boldsymbol{a}\\) y \\(\\boldsymbol{b}\\). Modelo Uniforme. \\(f(x)=\\left\\{\\begin{array}{cc}\\frac{1}{b-a} & x \\in[a, b] \\\\ 0 & x \\notin[a, b]\\end{array}\\right\\}\\)\nEstatura de una persona elegida al azar en una población. Modelo Normal.\n\n\\[\nf(x)=\\frac{1}{\\sqrt{2 \\pi}} e^{\\frac{-(x-170)^{2}}{2}}-\\infty&lt;x&lt;\\infty\n\\]\n\n\n2.7.3 Relaciones entre la función de distribución y la función de densidad.\nPara una variable continua, la relación entre las funciones de distribución y de densidad viene dada directamente a través de la definición. La función de distribución en un punto se obtiene integrando el valor de la función de densidad desde menos infinito hasta el punto en cuestión. Por ejemplo:\n\\[\nF(x)=\\int_{-\\infty}^{x} f(t) d t\n\\]\n\n2.7.3.1 Probabilidad de intervalos\nA partir de las funciones de densidad y de distribución, y teniendo en cuenta que \\(P(X=x)=0\\) para todo \\(x\\) real, es posible expresar las probabilidades para cualquier posible intervalo de valores de la variable. Por ejemplo:\n\n\n\nIntervalo\n\n\n\n\n\\(P(X \\leq a)=P(X&lt;a)=F(a)=\\int_{-\\infty}^{a} f(x) d x\\)\n\n\n\\(P(X \\geq a)=P(X&gt;a)=1-F(a)=\\int_{a}^{+\\infty} f(x) d x\\)\n\n\n\\(P(a&lt;X \\leq b)=P(a&lt;X&lt;b)=P(a \\leq X \\leq b)=P(a \\leq X&lt;b)\\)\n\n\n\\(=F(b)-F(a)=\\int^{b} f(x) d x\\)\n\n\n\nFijémonos que la probabilidad de los intervalos se corresponde con el área bajo la función de densidad dentro del intervalo considerado.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#independencia-de-variables-aleatorias",
    "href": "02-variablesAleatorias.html#independencia-de-variables-aleatorias",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.8 Independencia de variables aleatorias",
    "text": "2.8 Independencia de variables aleatorias\nDe manera intuitiva podemos decir que dos variables aleatorias son independientes si los valores que toma una de ellas no afectan a los de la otra ni a sus probabilidades.\nEn muchas ocasiones la independencia será evidente a partir del experimento, por ejemplo, es independiente el resultado del lanzamiento de un dado y el de una moneda, por tanto las variables Puntuación obtenida con el dado y Número de caras obtenidas al lanzar la moneda una vez serán variables independientes.\nEn otras ocasiones tenemos una dependencia clara, por ejemplo, al lanzar un dado consideremos las variables \\(X=\\) puntuación del dado \\(Y=\\) variable indicadora de puntuación par Es evidente que existe una clara dependencia, si sabemos que \\(Y=1\\), la variable \\(X\\) sólo puede tomar los valores 2 , 4 o 6 ; si sabemos que \\(X=3\\), entonces, \\(Y=0\\) forzosamente.\nAlgunas veces podemos suponer la existencia de una cierta relación entre variables, aunque sea en forma algo abstracta y sin concretar. Por ejemplo si realizamos unas mediciones sobre unos individuos, las variables altura en cm y peso en Kg probablemente estarán relacionadas, los valores de una influirán en los valores de la otra. Intentar determinar la naturaleza exacta de la relación entre ambas es lo que en estadística conocemos como un problema de regresión.\nSi queremos una definición algo más formal, basta con que recordemos que dos sucesos son independientes si la probabilidad de la intersección es igual al producto de probabilidades, aplicando esta definición a sucesos del tipo \\(X \\leq a\\) tenemos la definición siguiente:\n\n2.8.1 Caracterización de la independencia\nDiremos que dos variables aleatorias \\(X\\) e \\(Y\\) son independientes si y sólo si\n\\[\nP(X \\leq a \\cap Y \\leq b)=P(X \\leq a) \\cdot P(Y \\leq b)=F_{X}(a) \\cdot F_{Y}(b)\n\\]\nA la función \\(F(x, y)=P(X \\leq a \\cap Y \\leq b)\\) se la conoce como la función de distribución conjunta de \\(X\\) e \\(Y\\). Como consecuencia inmediata de la independencia de \\(X\\) e \\(Y\\), se cumple lo siguiente:\n\\[\nP(a&lt;X \\leq c \\cap b&lt;Y \\leq d)=P(a&lt;X \\leq c) \\cdot P(b&lt;Y \\leq d)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#caracterización-de-una-variable-aleatoria-a-través-de-parámetros",
    "href": "02-variablesAleatorias.html#caracterización-de-una-variable-aleatoria-a-través-de-parámetros",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.9 Caracterización de una variable aleatoria a través de parámetros",
    "text": "2.9 Caracterización de una variable aleatoria a través de parámetros\nHasta el momento hemos visto que toda variable aleatoria viene caracterizada a través de unas determinadas funciones matemáticas, las funciones de distribución y de densidad. Una vez caracterizada, y por tanto conocida, la distribución de una variable aleatoria, podemos obtener cualquier probabilidad asociada.\nEn ocasiones podemos acotar más el problema y reducir el estudio de una variable aleatoria a determinar una serie de características numéricas asociadas con la distribución de la variable. Dichas características tienen como propiedad fundamental el hecho de resumir gran parte de las propiedades de la variable aleatoria y juegan un papel muy destacado en las técnicas estadísticas que desarrollaremos a lo largo del curso.\nPor ejemplo, supuesta la pertenencia de una variable aleatoria a una determinada familia de distribuciones de probabilidad, bien sea discreta o continua, los diferentes miembros de la familia diferirán en el valor de esas características numéricas. En este caso, denominaremos a tales características los parámetros de la distribución.\nExiste un buen número de tales características, pero nos centraremos en las dos más importantes: la esperanza y la varianza. La primera nos informa sobre la localización de los valores de la variable y la segunda, sobre el grado de dispersión de estos valores.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#esperanza-de-una-variable-aleatoria-discreta",
    "href": "02-variablesAleatorias.html#esperanza-de-una-variable-aleatoria-discreta",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.10 Esperanza de una variable aleatoria discreta",
    "text": "2.10 Esperanza de una variable aleatoria discreta\nLa esperanza matemática de una variable aleatoria es una característica numérica que proporciona una idea de la localización de la variable aleatoria sobre la recta real. Decimos que es un parámetro de centralización o de localización.\nSu interpretación intuitiva o significado se corresponde con el valor medio teórico de los posibles valores que pueda tomar la variable aleatoria, o también con el centro de gravedad de los valores de la variable supuesto que cada valor tuviera una masa proporcional a la función de densidad en ellos.\nLa definición matemática de la esperanza en el caso de las variables aleatorias discretas se corresponde directamente con las interpretaciones proporcionadas en el párrafo anterior. Efectivamente, supuesta una variable aleatoria discreta \\(X\\) con recorrido \\(\\left\\{x_{1}, x_{2}, \\ldots, x_{k}, \\ldots\\right\\}\\) y con función de densidad \\(f(x)\\), se define la esperanza matemática de \\(X\\) como el valor\n\\[\nE(X)=\\sum_{x_{i} \\in X(\\Omega)} x_{i} f\\left(x_{i}\\right)\n\\]\ndonde el sumatorio se efectúa para todo valor que pertenece al recorrido de \\(X\\). En caso de que el recorrido sea infinito la esperanza existe si la serie resultante es absolutamente convergente, condición que no siempre se cumple.\nLa definición se corresponde con un promedio ponderado según su probabilidad de los valores del recorrido y, por tanto, se corresponde con la idea de un valor medio teórico.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#esperanza-de-una-variable-aleatoria-continua",
    "href": "02-variablesAleatorias.html#esperanza-de-una-variable-aleatoria-continua",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.11 Esperanza de una variable aleatoria continua",
    "text": "2.11 Esperanza de una variable aleatoria continua\nLa idea intuitiva que más nos puede ayudar en la definición de la esperanza matemática de una variable aleatoria continua es la idea del centro de gravedad de los valores de la variable, donde cada valor tiene una masa proporcional a la función de densidad en ellos.\nDada una variable aleatoria absolutamente continua \\(X\\) con función de densidad \\(f(x)\\), se define la esperanza matemática de \\(X\\) como el valor\n\\[\nE(X)=\\int_{-\\infty}^{+\\infty} x f(x) d x\n\\]\nsuponiendo que la integral exista.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#propiedades-de-la-esperanza-matemática",
    "href": "02-variablesAleatorias.html#propiedades-de-la-esperanza-matemática",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.12 Propiedades de la esperanza matemática",
    "text": "2.12 Propiedades de la esperanza matemática\n\nEsperanza de una función de una variable aleatoria\n\n\nVariable discreta\n\n\\[\nE(h(X))=\\sum_{x_{i} \\in X(\\Omega)} h\\left(x_{i}\\right) f\\left(x_{i}\\right)\n\\]\n\nVariable continua\n\n\\[\nE(h(X))=\\int_{-\\infty}^{+\\infty} h(x) f(x) d x\n\\]\n\n2.12.1 Linealidad de la esperanza matemática\n\n\\(E(X+Y)=E(X)+E(Y)\\)\n\\(E(k \\cdot X)=k \\cdot E(X)\\) para todo número real \\(k\\).\n\\(E(k)=k\\) para todo número real \\(k\\).\n\n○ \\(E(a \\cdot X+b)=a \\cdot E(X)+b\\) para todo par de números reales \\(a\\) y \\(b\\).\n\n\n2.12.2 Esperanza del producto\n\n\\(E(X \\cdot Y)=E(X) \\cdot E(Y)\\) únicamente en el caso de que \\(X\\) e \\(Y\\) sean variables aleatorias independientes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#varianza-de-una-variable-aleatoria",
    "href": "02-variablesAleatorias.html#varianza-de-una-variable-aleatoria",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.13 Varianza de una variable aleatoria",
    "text": "2.13 Varianza de una variable aleatoria\nLa varianza de una variable aleatoria es una característica numérica que proporciona una idea de la dispersión de la variable aleatoria respecto de su esperanza. Decimos que es un parámetro de dispersión.\nLa definición es la siguiente:\n\\[\n\\operatorname{Var}(X)=E\\left((X-E(X))^{2}\\right)\n\\]\nEs, por tanto, el promedio teórico de las desviaciones cuadráticas de los diferentes valores que puede tomar la variable respecto de su valor medio teórico o esperanza.\nEn el caso de las variables discretas, la expresión se convierte en:\n\\[\n\\operatorname{Var}(X)=\\sum_{x_{i} \\in X(\\Omega)}\\left(x_{i}-E(X)\\right)^{2} f\\left(x_{i}\\right)\n\\]\nmientras que para las variables continuas tenemos:\n\\[\n\\operatorname{Var}(X)=\\int_{-\\infty}^{+\\infty}(x-E(X))^{2} f(x) d x\n\\]\nEn ambos casos existe una expresión equivalente alternativa y generalmente de cálculo más fácil:\n\\[\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-(E(X))^{2}\n\\]\nUna de las características de la varianza es que viene expresada en unidades cuadráticas respecto de las unidades originales de la variable. Un parámetro de dispersión derivado de la varianza y que tiene las mismas unidades de la variable aleatoria es la desviación típica, que se define como la raíz cuadrada de la varianza.\n\\[\n\\sigma_{X}=\\sqrt{\\operatorname{Var}(X)}=\\sqrt{E\\left((X-E(X))^{2}\\right)}\n\\]\n\n2.13.1 Propiedades de la varianza\n\n\\(\\operatorname{Var}(X) \\geq 0\\)\n\\(\\operatorname{Var}(k \\cdot X)=k^{2} \\cdot \\operatorname{Var}(X)\\) para todo numero real \\(k\\).\n\\(\\operatorname{Var}(k)=0\\) para todo numero real \\(k\\).\n\\(\\operatorname{Var}(a \\cdot X+b)=a^{2} \\cdot \\operatorname{Var}(X)\\) para todo par de números reales \\(a\\) i \\(b\\).\n\\(\\operatorname{Var}(X+Y)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)\\) únicamente en el caso que \\(X\\) y \\(Y\\) sean independientes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#momentos-de-orden-k-de-una-variable-aleatoria",
    "href": "02-variablesAleatorias.html#momentos-de-orden-k-de-una-variable-aleatoria",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.14 Momentos (de orden \\(k\\)) de una variable aleatoria",
    "text": "2.14 Momentos (de orden \\(k\\)) de una variable aleatoria\n\nDada una variable aleatoria \\(X\\), definimos el momento de orden \\(k\\) como:\n\n\\[\nm_{k}=E\\left(X^{k}\\right)\n\\]\nsuponiendo que tal esperanza exista. Podemos ver que la esperanza es el momento de orden \\(1, E(X)=m_{1}\\).\n\nDefinimos el momento central de orden \\(k\\) como:\n\n\\[\n\\mu_{k}=E\\left((X-E(X))^{k}\\right)\n\\]\nCon la denominación anterior, la varianza es el momento central de orden \\(2, \\operatorname{Var}(X)=\\mu_{2}\\).\n\nEs posible también definir momentos mixtos de dos variables aleatorias. Dadas dos variables aleatorias \\(X\\) e \\(Y\\) definimos el momento mixto de orden \\((r, k)\\) como\n\n\\[\nm_{r k}=E\\left(X^{r} \\cdot Y^{k}\\right)\n\\]\ny el momento mixto central de orden \\((r, k)\\) como\n\\[\n\\left.\\mu_{r k}=E(X-E(X))^{r} \\cdot(Y-E(Y))^{k}\\right)\n\\]\n\nEl momento mixto central más importante es el \\(\\mu_{11}\\), denominado la covarianza de \\(X\\) e \\(Y\\), y con una interpretación en el sentido de cuantificar el grado de dependencia entre dos variables aleatorias, puesto que si \\(X\\) e \\(Y\\) son independientes se verifica que \\(\\mu_{11}=0\\), mientras que si \\(\\mu_{11} \\neq 0\\) entonces las variables son dependientes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "02-variablesAleatorias.html#definición-formal-de-variable-aleatoria",
    "href": "02-variablesAleatorias.html#definición-formal-de-variable-aleatoria",
    "title": "2  Variables aleatorias y Distribuciones de probabilidad",
    "section": "2.15 Definición formal de variable aleatoria",
    "text": "2.15 Definición formal de variable aleatoria\nTal como hemos comentado, la definición formal de variable aleatoria impone una restricción matemática en la formulación vista hasta el momento.\nDefiniremos una variable aleatoria como una aplicación de \\(\\Omega\\) en el conjunto de números reales\n\\[\n\\begin{aligned}\nX: \\Omega & \\rightarrow \\mathbb{R} \\\\\n\\omega & \\rightarrow X(\\omega)\n\\end{aligned}\n\\] que verifique la propiedad siguiente\n\\[\n\\forall x \\in \\mathbb{R} \\quad \\text { el conjunto } \\mathrm{A}=\\{a \\mid \\mathrm{X}(a) \\leq \\mathrm{x}\\} \\text { es un suceso observable }\n\\]\nes decir, para todo número real \\(x\\), el conjunto de resultados elementales tales que la variable aleatoria toma sobre ellos valores inferiores o iguales a \\(x\\) ha de ser un suceso sobre el cual podamos definir una probabilidad.\nDicha propiedad recibe el nombre de medibilidad y por tanto podríamos decir que una variable aleatoria es una función medible de \\(\\Omega\\) en los reales.\nEsta condición nos asegura que podremos calcular sin problemas, probabilidades sobre intervalos de la recta real a partir de las probabilidades de los sucesos correspondientes.\n\\[\nP(X \\leq x)=P\\{\\omega \\mid X(\\omega) \\leq x\\}\n\\]\nLa expresión anterior se leería de la manera siguiente: La probabilidad de que la variable aleatoria tome valores inferiores o iguales a \\(x\\) es igual a la probabilidad del suceso formado por el conjunto de resultados elementales sobre los que el valor de la variable es menor o igual que \\(x\\).\nLa probabilidad obtenida de esta manera se denomina probabilidad inducida. Se puede comprobar que, a partir de la condición requerida, se pueden obtener probabilidades sobre cualquier tipo de intervalo de la recta real. Por ejemplo:\n\\[\nP(a&lt;X \\leq b)=P(X \\leq b)-P(X \\leq a)\n\\]\nLa condición exigida para ser variable aleatoria discreta ahora puede ser expresada como:\n\\[\n\\forall k=1,2, \\ldots \\text { el conjunto } \\mathrm{A}=\\left\\{\\omega \\mid \\mathrm{X}(\\omega)=\\mathrm{x}_{\\mathrm{k}}\\right\\}=\\mathrm{X}^{-1}\\left(\\left\\{\\mathrm{x}_{\\mathrm{k}}\\right\\}\\right) \\text { es un suceso observable }\n\\]\nToda variable aleatoria definida sobre un espacio de probabilidad finito es necesariamente discreta. La suma y el producto de variables aleatorias discretas, definido por:\n\\[\n(X+Y)(w)=X(w)+Y(w) \\text { y }(X \\cdot Y)(w)=X(w) \\cdot Y(w)\n\\]\nes también una variable aleatoria discreta.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Variables aleatorias y Distribuciones de probabilidad</span>"
    ]
  },
  {
    "objectID": "03-distribucionesNotables.html",
    "href": "03-distribucionesNotables.html",
    "title": "3  Distribuciones Notables",
    "section": "",
    "text": "3.1 Distribuciones discretas",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuciones Notables</span>"
    ]
  },
  {
    "objectID": "03-distribucionesNotables.html#distribuciones-discretas",
    "href": "03-distribucionesNotables.html#distribuciones-discretas",
    "title": "3  Distribuciones Notables",
    "section": "",
    "text": "3.1.1 La distribución de Bernouilli\nEs el modelo discreto más sencillo en que podamos pensar. Hace referencia a situaciones en las que el resultado de un experimento sólo puede ser: se ha dado el suceso \\(A\\) ó no se ha dado el suceso \\(A\\). Por ejemplo, en el lanzamiento de una moneda sólo puede darse el suceso sale cara o su complementario no sale cara (sale cruz).\nPor lo tanto, definimos la variable aleatoria \\(X\\) de la siguiente manera:\n\n\\(X=1\\) si se ha dado \\(A\\).\n\\(X=0\\) si no se ha dado \\(A\\), es decir, se ha dado el complementario \\(A^{c}\\).\n\nSi además, conocemos la probabilidad de que suceda \\(A\\) :\n\\[\nP[A]=p\n\\]\ny, por tanto,\n\\[\nP\\left[A^{c}\\right]=1-p\n\\]\nya podemos definir la distribución de la variable aleatoria \\(X\\). En estas condiciones diremos que \\(X\\) sigue una distribución de Bernouilli de parámetro \\(p\\), que abreviaremos así \\(X \\sim \\operatorname{Bernouilli}(p)\\), y su función de densidad se define así:\n\\[\nf(k)=P[X=k]=\\left\\{\\begin{array}{cc}\np & \\text { si } k=1(\\text { se ha dado } A) \\\\\n1-p & \\text { si } k=0\\left(\\text { se ha dado } A^{c}\\right)\n\\end{array}\\right\\}\n\\]\nGráficamente:\n\nMientras que la función de distribución será:\n\\[\nF(k)=P[X \\leq k]=\\left\\{\\begin{array}{lc}\n0 & \\text { si } \\mathbf{k}&lt;0 \\\\\n\\mathbf{p} & \\text { si } 0 \\leq \\mathbf{k}&lt;1 \\\\\n1 & \\text { si } \\mathbf{p} \\geq 1\n\\end{array}\\right\\}\n\\]\nGráficamente:\n\n\n3.1.1.1 Propiedades del modelo de Bernouilli\n\nLa esperanza vale \\(E(X)=p\\).\nLa varianza vale \\(V(X)=p(1-p)\\).\n\n\n\n\n3.1.2 La distribución Binomial\nAl igual que el modelo de Bernouilli, hace referencia a experiencias con resultados dicotómicos (el resultado sólo puede ser \\(A\\) o \\(A^{\\mathcal{C}}\\) ). Sin embargo en este modelo estamos interesados en la repetición de \\(n\\) veces una experiencia de este tipo en condiciones independientes.\nTomemos el ejemplo del contaje del número de caras en el lanzamiento \\(n\\) veces de una moneda regular. Para concretar, vamos a suponer que disponemos de una moneda regular \\((P[\\) cara \\(]=P[c r u z]=1 / 2)\\) que lanzamos cuatro veces. Es evidente que, en estas condiciones, la variable X: número de caras en cuatro lanzamientos independientes de una moneda regular es una variable aleatoria discreta que sólo puede tomar cinco posibles valores:\n\\[\nx=0,1,2,3,4\n\\]\nPasemos ahora a calcular la probabilidad de cada valor (en terminología estadística, vamos a calcular la función de densidad de la variable \\(X\\) ).\nEs evidente que la \\(P[X=0]\\) es igual a la probabilidad de salgan cuatro cruces seguidas:\n\\[\nP[X=0]=P[c r u z, c r u z, c r u z, c r u z]=\\mathrm{P}[c r u z]^{4}=(1 / 2)^{4}=0,0625\n\\]\nya que la moneda es regular y, por tanto, \\(P[\\) cara \\(]=P[\\) cruz \\(]=1 / 2\\). La \\(P[X=3]\\) corresponde al suceso de que salgan tres caras ( \\(c\\) en adelante) y una cruz ( + en adelante). Sin embargo, en este caso tenemos hasta cuatro posibles maneras de obtener dicho resultado, según el orden en que aparezcan las tres caras y la cruz:\n\n\n\n\n\n\n\n\n\n+ccc\n\\(\\mathrm{c}+\\mathrm{cc}\\)\n\\(\\mathrm{cc}+\\mathrm{c}\\)\n\\(\\mathrm{ccc}+\\)\n\n\n\n\n\nTambién debería resultar evidente que la probabilidad de cada uno de estos sucesos es la misma:\n\\[\nP[+\\mathrm{ccc}]=P[\\mathrm{c}+\\mathrm{cc}]=P[\\mathrm{cc}+\\mathrm{c}]=P[\\mathrm{ccc}+]=(1 / 2)^{4}=(1 / 2)^{4}=0,0625\n\\]\nde manera que, finalmente, la probabilidad de que salgan tres caras y una cruz es la suma de las probabilidades de los 4 casos anteriores:\n\\[\nP[X=3]=4(1 / 2)^{4}=0,25\n\\]\nY así podríamos ir calculando el resto de casos. Podemos ver que, en este ejemplo, todos los casos tienen la misma probabilidad \\((0,0625)\\) y que el número total de casos posibles es 16 . En términos de combinatoria dicho número se obtendría como variaciones con repetición de dos valores (cara o cruz) tomados de cuatro en cuatro (el número de lanzamientos de la moneda):\n\\[\nV R_{2}{ }^{4}=2^{4}=16\n\\]\nEn la siguiente tabla se muestran los dieciséis posibles resultados:\n\n\n\n\\(k=\\) número de  caras\nCasos\n\n\n\n\n0\n+++++\n\n\n1\n+++c\n\n\n\n\\(++\\mathrm{c}+\\)\n\n\n\n\\(+\\mathrm{c}++\\)\n\n\n\n\\(\\mathrm{c}+++\\)\n\n\n\n++cc\n\n\n\n\\(+\\mathrm{c}+\\mathrm{c}\\)\n\n\n\n\\(\\mathrm{c}++\\mathrm{c}+\\)\n\n\n\n\\(\\mathrm{c}+\\mathrm{c}+\\)\n\n\n\ncc++\n\n\n\n\\(\\mathrm{ccc}+\\)\n\n\n\n\\(\\mathrm{c}+\\mathrm{cc}\\)\n\n\n\nSi hacemos uso de nuestros conocimientos de combinatoria, comprobamos que el número de casos para cada posible valor \\(k(k=0,1,2,3,4)\\) puede calcularse como permutaciones con repetición de cuatro elementos tomado de \\(k\\) y \\(4-k\\) :\n\\[\nR P_{4}^{k, 4-k}=\\frac{4!}{k!(4-k)!}=\\binom{4}{k}\n\\]\ny obtenemos finalmente el número combinatorio 4 sobre \\(k\\). En efecto, para el caso \\(k=3\\), tendríamos:\n\\[\n\\binom{4}{3}=\\frac{4!}{3!1!}=4\n\\]\nque son los cuatro posibles casos que nos dan tres caras y una cruz. Finalmente, recordando que todos los casos tienen la misma probabilidad, se construye la siguiente tabla:\n\n\n\n\\(k=\\) número de caras\nNúmero de casos\n\\(P[X=k]\\)\n\n\n\n\n0\n1\n0,0625\n\n\n1\n4\n0,2500\n\n\n\n\n\n\n\n\n\n\n\n2\n6\n0,3750\n\n\n\n\n3\n4\n0,2500\n\n\n4\n1\n0,0625\n\n\nTotal\n16\n1\n\n\n\n\n3.1.2.1 Los parámetros de la distribución Binomial\nLa última tabla de la página anterior es, justamente, la función de densidad de nuestra variable \\(X\\).\n\n\n\nFunción de densidad de \\(X\\)\n\n\n\n\n\n\\(k\\)\n\\(P[X=k]\\)\n\n\n0\n0,0625\n\n\n1\n0,2500\n\n\n2\n0,3750\n\n\n3\n0,2500\n\n\n4\n0,0625\n\n\nEn otro caso\n0\n\n\n\nComo hemos visto, para obtener los resultados anteriores, hemos tenido que definir dos valores:\n\n\\(n\\) : el número de lanzamientos (repeticiones de la experiencia aleatoria en condiciones independientes), en nuestro caso \\(n=4\\).\n\\(p\\) : la probabilidad de que salga cara \\((P[c])\\), en nuestro caso \\(p=1 / 2\\).\n\nSe dice, por tanto, que la distribución Binomial depende de dos parámetros: \\(n\\) y \\(p\\). En nuestro ejemplo, diremos que \\(X\\) sigue una distribución Binomial de parámetros \\(n=4\\) i \\(p=1 / 2\\). De forma abreviada:\n\\[\nX \\sim B(n=4 ; p=1 / 2)\n\\]\nEn el ejemplo que hemos visto, suponíamos que la moneda era regular y, por tanto,\n\\[\nP[c]=P[+]=1 / 2\n\\]\nSi tenemos una moneda trucada con las siguientes probabilidades:\n\\[\nP[c]=2 / 3 \\quad \\text { i } \\quad P[+]=1 / 3\n\\]\ndiremos que en este caso la variable \\(X\\) : número de caras en cuatro lanzamientos independientes de nuestra moneda trucada sigue una distribución Binomial de parámetros:\n\\[\nX \\sim B(n=4 ; p=2 / 3)\n\\]\nEl problema se nos complica levemente ya que ahora no todos los posibles resultados tienen la misma probabilidad. Veamos dos ejemplos:\n\nLa probabilidad de obtener cuatro caras es:\n\n\\[\nP[c c c c]=(2 / 3)^{4}=0,1975\n\\]\n\nLa probabilidad de que el primer lanzamiento sea cara y el resto sean cruces valdrá:\n\n\\[\nP\\left[c^{+++}\\right]=(2 / 3)^{\\prime}(1 / 3)^{3}=0,0247\n\\]\nSin embargo sí se cumplirá que la probabilidad de que todos los caso que resulten en el mismo número de caras y cruces tendrán la misma probabilidad. Por ejemplo, para los cuatro casos en los que el número total de caras es 1 y el de cruces 3 :\n\\[\nP[c+++]=P[+c++]=P[++c+]=P[+++c]=(2 / 3)^{\\prime}(1 / 3)^{3}=0,0247\n\\]\nY, por tanto, la probabilidad de obtener una sola cara en el lanzamiento de nuestra moneda trucada será:\n\\[\nP[X=1]=4^{\\prime} 0,0247=0,0988\n\\]\nO, generalizando, si \\(P[A]=p\\) y \\(P\\left[A^{c}\\right]=1-p\\) tenemos que\n\\[\nP[X=k]=c(n, k) p^{k}(1-\\mathrm{p})^{n-k} \\quad \\text { si } k=0,1, \\ldots, n\n\\]\ndonde \\(c(n, k)\\) representa el número de posibles resultados en los que obtenemos \\(k\\) caras y \\(n-k\\) cruces en \\(n\\) lanzamientos. Tal como hemos visto, dicho número se puede calcular como permutaciones con repetición de \\(n\\) unidades tomadas de \\(k\\) y \\(n-k\\).\nTodo lo anterior nos lleva a formular el model binoial a traves de la siguiente función de densidad:\n\\[\nf(k)=P[X=k]=\\left\\{\\begin{array}{ll}\n\\binom{\\mathbf{n}}{\\mathbf{k}} p^{k}(1-p)^{n-k} & \\text { si } \\quad k=0, \\ldots, n \\\\\n0 & \\text { en caso contrario }\n\\end{array}\\right\\}\n\\]\ncon lo que la función de distribución se calcularía:\n\\[\nF(k)=P[X \\leq k]=\\left\\{\\begin{array}{cc}\n0 & \\text { si } k&lt;0 \\\\\n\\sum_{i=0}^{k}\\binom{\\mathbf{i}}{\\mathbf{n}} p^{i}(\\mathbf{1}-p)^{n-i} \\\\\n\\mathbf{1} & \\text { si } k \\geq n\n\\end{array}\\right\\}\n\\]\nEn el programa siguiente se muestra la forma de la función de densidad junto con los valores de la función de densidad y de la función de distribución para cualquier valor:\n\n\n\n\n\n\nAVIS\n\n\n\nPosar un exemple de com fer-ho amb R\n\n\n\n\n3.1.2.2 Propiedades del modelo Binomial\n\nLa esperanza vale \\(E(X)=n p\\).\nLa varianza es \\(V(X)=n p(1-p)\\).\nEs una generalización del modelo de Bernouilli. En efecto, la Binomial con \\(n=1\\) (una sola realización) coincide con la distribución de Bernouilli.\nLa suma de dos variables aleatorias binomiales independientes con igual parámetro \\(p\\) también sigue una distribución Binomial:\n\n\\[\nX_{1} \\sim B\\left(n=n_{1} ; p=p_{0}\\right) \\quad \\text { i } \\quad X_{2} \\sim B\\left(n=n_{2} ; p=p_{0}\\right)\n\\]\nSi definimos \\(Z=X_{1}+X_{2}\\) entonces,\n\\[\nZ \\sim B\\left(n=n_{1}+n_{2} ; p=p_{0}\\right)\n\\]\n\n\n\n3.1.3 La distribución de Poisson\nSe trata de un modelo discreto, pero en el que el conjunto de valores con probabilidad no nula no es finito, sino numerable. Se dice que una variable aleatoria \\(X\\) sigue la distribución de Poisson si su función de densidad viene dada por:\n\\[\nf(k)=P[X=k]=\\left\\{\\begin{array}{ll}\ne^{-\\lambda \\frac{\\lambda^{k}}{k!}} & \\text { si } k=0,12, \\ldots \\\\\n0 & \\text { en caso contrario }\n\\end{array}\\right\\}\n\\]\nComo vemos, este modelo se caracteriza por un sólo parámetro \\(\\lambda\\), que debe ser positivo. Esta distribución suele utilizarse para contajes del tipo número de individuos por unidad de tiempo, de espacio, etc.\n\n3.1.3.1 Propiedades del modelo de Poisson\n\nEsperanza: \\(E(X)=\\lambda\\).\nVarianza: \\(V(X)=\\lambda\\).\n\nEn esta distribución la esperanza y la varianza coinciden.\n\nLa suma de dos variables aleatorias independientes con distribución de Poisson resulta en una nueva variable aleatoria, también con distribución de Poisson, de parámetro igual a la suma de parámetros:\n\n\\[\nX_{1} \\sim P\\left(\\lambda=\\lambda_{1}\\right) \\quad \\text { y } \\quad X_{2} \\sim P\\left(\\lambda=\\lambda_{2}\\right)\n\\]\ny definimos \\(Z=X_{1}+X_{2}\\), entonces,\n\\[\nZ \\sim P\\left(\\lambda=\\lambda_{1}+\\lambda_{2}\\right)\n\\]\nEste resultado se extiende inmediatamente al caso de \\(n\\) variables aleatorias independientes con distribución de Poisson. En este caso, la variable suma de todas ellas sigue una distribución de Poisson de parámetro igual a la suma de los parámetros.\n\n\n\n3.1.4 La distribución Multinomial\n\n\n\n\n\n\nCOMPTE:Distribució Multivariant!\n\n\n\nUsing callouts is an effective way to highlight content that your reader give special consideration or attention.\n\n\nEste modelo se puede ver como una generalización del Binomial en el que, en lugar de tener dos posibles resultados, tenemos \\(r\\) resultados posibles.\nSupongamos que el resultado de una determinada experiencia puede ser \\(r\\) valores distintos: \\(A_{1}, A_{2}, \\ldots\\) \\(A_{r}\\) cada uno de ellos con probabilidad \\(p_{1}, p_{2}, \\ldots, p_{r}\\), respectivamente.\n\\[\nP\\left(A_{1}\\right)=p_{1} ; \\quad P\\left(A_{2}\\right)=p_{2} ; \\quad \\cdots \\quad P\\left(A_{r}\\right)=p_{r} ; \\quad \\text { con } \\quad \\sum_{i=1}^{r} P\\left(A_{i}\\right)=1\n\\]\nSi repetimos la experiencia \\(n\\) veces en condiciones independientes, podemos preguntarnos la probabilidad de que el suceso \\(A_{1}\\) aparezca \\(k_{1}\\) veces, el suceso \\(A_{2}, k_{2}\\) veces y así sucesivamente:\n\\[\nP\\left[\\left(A_{1}=k_{1}\\right) \\cap\\left(A_{1}=k_{2}\\right) \\cap \\cdots \\cap\\left(A_{r}=k_{r}\\right)\\right]\n\\]\nAl modelo estadístico que nos da dicha probabilidad se le denomina Multinomial, y su función de densidad viene dada por:\n\\[\n\\begin{gathered}\nf\\left(k_{1}, k_{2}, \\ldots, k_{r}\\right)=P\\left[\\left(A_{1}=k_{1}\\right) \\cap\\left(A_{1}=k_{2}\\right) \\cap \\cdots \\cap\\left(A_{r}=k_{r}\\right)\\right]=\\frac{n!}{k_{1}!k!\\cdots k_{r}!} p_{1}^{k_{1}} p_{2}^{k_{2}} \\cdots p_{r}^{k_{r}} \\\\\n\\operatorname{con} \\sum_{i=1}^{r} P\\left(A_{i}\\right)=1 \\quad \\text { y } \\quad \\sum_{i=1}^{r} k_{i}=n\n\\end{gathered}\n\\]\ncomo se ve, el modelo Multinomial queda definido por los parámetros \\(\\left(n, p_{1}, p_{2}, \\ldots, p_{r}\\right)\\). La fórmula anterior puede deducirse de forma análoga al caso Binomial. En realidad, si tomamos \\(r=2\\) tenemos exactamente el modelo Binomial.\nSe debe destacar que este modelo es un ejemplo de distribución multivariante, es decir, de distribución conjunta de varias ( \\(r\\) ) variables aleatorias. En efecto, si definimos la variable aleatoria \\(X_{1}\\) como número de veces que se produce el suceso \\(A_{1}\\) de un total de n experiencias, y así sucesivamente, tenemos un conjunto de \\(r\\) variables aleatorias discretas cuya función de densidad conjunta (valorada a la vez) viene definida por la anterior fórmula. Nótese que si consideramos cada una de estas variables \\(X_{i}(i=1,2, \\ldots, r)\\) por separado, su distribución es la Binomial de parámetros \\(n\\) y \\(p_{i}\\).\n\n3.1.4.1 La distribución Uniforme discreta\nTenemos esta distribución cuando el resultado de una experiencia aleatoria puede ser un conjunto finito de \\(n\\) posibles resultados, todos ellos igualmente probables.\nUn ejemplo puede ser la variable \\(X\\), puntuación en el lanzamiento de un dado regular. Esta variable toma seis valores posibles, todos con la misma probabilidad \\(p=1 / 6\\). La función de densidad de esta variable será:\n\\[\nf(k)=P[X=k]=1 / 6 \\quad k=1,2,3,4,5,6\n\\]\n\nEn general, si la variable \\(X\\) puede tomar \\(n(k=1,2, \\ldots, n)\\) valores, todos con igual probabilidad, su función de densidad será:\n\\[\nf(k)=P[X=k]=1 / n \\quad k=1,2, \\ldots, n\n\\]\n\n\n3.1.4.2 Propiedades del modelo Uniforme discreto\nSea \\(n\\) el número de valores equiprobables posibles:\n\n\n3.1.4.3 Esperanza:\n\\[\nE(X)=\\frac{n+1}{2}\n\\]\n\n\n3.1.4.4 Varianza:\n\\[\nV(X)=\\frac{(n+1)[2(2 n+1)-3(n+1)]}{12}\n\\]\n\n\n\n3.1.5 La distribución Hipergeométrica\nEste modelo presenta similitudes con el Binomial, pero sin la suposición de independencia de éste último. Veámoslo:\n\nPartimos de un conjunto formado por \\(N\\) individuos divididos en dos categorías mutuamente excluyentes: \\(A\\) y \\(A^{c}\\); de manera que \\(N_{1}\\) individuos pertenecen a la categoría \\(A\\) y \\(N_{2}\\) individuos, a la categoría \\(A^{c}\\). Por tanto, se cumple que\n\n\\[\nN=N_{1}+N_{2}\n\\]\n\nSi del conjunto anterior extraemos \\(n\\) individuos sin reemplazamiento \\((n \\leq N)\\), la variable \\(X\\) que representa el número k de individuos que pertenecen a la categoría A (de los n extraídos) tiene por función de densidad:\n\n\\[\nf(k)=P[X=k]=\\frac{\\binom{\\mathbf{N}_{1}}{\\mathbf{k}}\\binom{\\mathrm{N}_{2}}{\\mathbf{n}-\\mathbf{k}}}{\\binom{\\mathbf{N}}{\\mathbf{k}}}\n\\]\nsi \\(\\operatorname{máx}\\left\\{0, \\mathrm{n}-N_{2}\\right\\} \\leq \\mathrm{k} \\leq \\min \\left\\{N_{1}, n\\right\\}\\)\nLa dependencia se debe al hecho de que \\(N\\) es finito y las extracciones se efectúan sin reemplazamiento. El caso de extracciones con reemplazamiento sería equivalente al de \\(N\\) infinito y se resolvería mediante el modelo Binomial.\nEl programa siguiente nos muestra la forma de la función de densidad de esta variable y el valor de la función de densidad y de la función de distribución en el punto que elijamos:\n\n3.1.5.1 Propiedades del modelo hipergeométrico\n\nEsperanza: \\(\\mathrm{E}(\\mathrm{X})=\\mathrm{n} \\mathrm{N}_{1} / \\mathrm{N}_{2}\\).\nVarianza: \\(V(X)=\\left(n N_{1} N_{2}(N-n)\\right) /\\left(N_{2}(N-1)\\right)\\)\n\n\n\n\n\n\n\n\n\n\n3.1.6 La distribución Geométrica o de Pascal\nDefinamos una experiencia aleatoria cuyo resultado sólo puede ser el suceso \\(A\\) o su complementario \\(A^{c}\\), y que se repite secuencialmente hasta que aparece el suceso \\(A\\) por primera vez.\nDefinamos la variable aleatoria \\(X\\) como el número de veces que repetimos la experiencia en condiciones independientes hasta que se dé A por primera vez. Bajo estas condiciones, decimos que la variable \\(X\\) sigue una distribución geométrica o de Pascal de parámetro \\(p=P(A)\\).\nLa función de densidad puede deducirse fácilmente de la definición:\n\\[\nf(k)=P[X=k]=(1-p)^{k} p \\quad k=0,1,2, \\ldots\n\\]\nEn el programa siguiente podéis ver su forma y obtener los valores de la función de densidad y de la de distribución:\nAlgunas puntualizaciones de la definición de \\(X\\) :\n\nNotése que, en esta definición, condiciones independientes significa que \\(p\\), la probabilidad de \\(A\\), y \\(1-p\\), la de su complementario \\(A^{c}\\), no varían a lo largo de las sucesivas repeticiones de la experiencia.\nTal y como la hemos definido, \\(X\\) se refiere al número de lanzamientos hasta que se produce \\(A\\), pero sin contabilizar el último caso en que se da \\(A\\). Por dicha razón \\(X\\) puede tomar los valores \\(k=\\) \\(0,1,2, \\ldots\\) con probabilidad no nula.\n\nUn ejemplo de este modelo podría ser la experiencia consistente en lanzar sucesivamente un dado regular hasta que aparezca el número 6 . Si definimos la variable aleatoria \\(X\\) como el número de lanzamientos de un dado regular hasta que aparezca un 6 , queda claro que \\(X\\) sigue una distribución geométrica de parámetro \\(p=1 / 6\\).\n\n3.1.6.1 Propiedades del modelo Geométrico o de Pascal\n\nEsperanza: \\(E(X)=(1-p) / p\\)\nVarianza: \\(V(X)=(1-p) / p^{2}\\)\n\n\n\n3.1.6.2 Preguntas:\n\n¿A que suceso nos referimos cuando decimos \\(X=0\\) ? Respuesta.\n\nCuando decimos que \\(X=0\\) nos referimos al caso en que el 6 aparece en el primer lanzamiento. La probabilidad de que esto suceda, suponiendo un dado regular, es de \\(1 / 6\\) :\n\n\n\\[\nP[X=0]=1 / 6\n\\]\n\n¿Cuál es la probabilidad de que el primer 6 aparezca en el cuarto lanzamiento? Respuesta.\n\nLa probabilidad de que el primer 6 aparezca en el cuarto lanzamiento corresponde a:\n\n\n\\[\nP[X=3]=(5 / 6)^{3 \\cdot} 1 / 6=0,0965\n\\]\nFijémonos en que, si definimos \\(A\\) como el suceso sale un 6, la probabilidad anterior corresponde a la del suceso: \\(\\left\\{A^{c} A^{c} A^{c} A\\right\\}\\) (en este orden).\n\n\n\n3.1.7 La distribución Binomial negativa\nPuede definirse como una generalización del modelo Geométrico o de Pascal. Así, dado un suceso \\(A\\) y su complementario \\(A^{c}\\), cuando \\(X\\) representa el número de veces que se da \\(\\mathrm{A}^{\\mathrm{c}}\\) (ausencias, fallos, etc.) hasta que se produce r veces el suceso A , en una serie de repeticiones de la experiencia aleatoria en condiciones independientes, decimos que \\(X\\) sigue la distribución Binomial negativa. Nótese que, cuando \\(r=1\\), tenemos exactamente el modelo geométrico.\nEste modelo queda definido por dos parámetros \\(p\\) (la probabilidad de \\(A: p=P(A)\\) ) y \\(r\\) (el número de veces que debe producirse \\(A\\) para que detengamos la experiencia).\nLa función de densidad viene dada por:\n\\[\nf(k)=P[X=k]=\\binom{\\mathbf{k}+\\mathbf{r}-\\mathbf{1}}{\\mathbf{r}-\\mathbf{1}} \\mathbf{p}^{\\mathbf{r}} \\mathbf{q}^{\\mathbf{k}} \\quad \\mathbf{k}=\\mathbf{0}, \\mathbf{1}, \\mathbf{2}, \\ldots\n\\]\ndonde \\(q\\) representa el complementario de \\(p: q=1-p\\).\n\n3.1.7.1 Propiedades del modelo Binomial negativo\n\nEsperanza: \\(E(X)=r^{\\prime} q / p\\)\nVarianza: \\(V(X)=r^{\\prime} q / p^{2}\\)\nSe cumplen las siguientes propiedades respecto la función de densidad:\n\n\\[\nf(0)=p^{r} \\quad \\text { y } \\quad f(k+1)=\\frac{(1-p)(k+r)}{k+1} f(k)\n\\]\n\nEste modelo se ajusta bien a contajes (números de individuos por unidad de superficie) cuando se produce una distribución contagiosa (los individuos tienden a agruparse).\nLa distribución Binomial negativa puede definirse con mayor generalidad si tomamos \\(r\\) como un número real positivo cualquiera (no necesariamente entero). Pero, en dicho caso, se pierde el carácter intuitivo del modelo y se complican ligeramente los cálculos. Por dichas razones, se ha excluido dicha posibilidad en esta presentación.\n\n\n\n\n3.1.8 Tabla resumen de las distribuciones discretas principales\n\n\n\n\n\n\n\n\n\n\nDistribución\nParámetros\nFunción de densidad\nEsperanza\nVarianza\n\n\n\n\nBernouilli\n\\(0 \\leq p \\leq 1\\)\n\\(p^{k}(1-p)^{1-k}\\)  \\(k=0,1\\)\n\\(p\\)\n\\(p(1-p)\\)\n\n\nBinomial\n\\(0 \\leq p \\leq 1\\)  \\(n=1,2, \\ldots\\)\n\\(\\binom{\\mathbf{n}}{\\mathbf{k}} p^{k}(1-p)^{n-k}\\)  \\(k=0,1, \\ldots, n\\)\n\\(n p\\)\n\\(n p(1-p)\\)\n\n\nPoisson\n\\(\\lambda&gt;0\\)\n\\(e^{-\\lambda} \\frac{\\lambda^{k}}{k!}\\)  \\(k=012, \\ldots\\)\n\\(\\lambda\\)\n\\(\\lambda\\)\n\n\nMultinomial\n\\(0 \\leq p_{1}, \\ldots\\)  \\(p_{r} \\leq 1\\)  \\(\\left(p_{1}+\\ldots+\\right.\\)  \\(\\left.p_{\\mathrm{r}}=1\\right)\\)  \\(n=1,2\\)\n\\(\\frac{n!}{k_{1}!k_{2}!\\cdots k_{r}!} p_{1}^{k_{1}} p_{2}^{k_{2}} \\cdots p_{r}^{k_{r}}\\)  \\(\\sum_{i=1}^{r} k_{i}=n\\)\n\\(\\left(\\begin{array}{c}n p_{1} \\\\ n p_{2} \\\\ \\vdots \\\\ n p_{r}\\end{array}\\right)\\)\n\\(\\boldsymbol{\\sigma}_{i i}=n p_{i}\\left(1-p_{i}\\right)\\)  \\(\\boldsymbol{\\sigma}_{i j}=n p_{i} p_{j} \\quad i \\neq j\\)\n\n\nUniforme  discreta\n\\(n=1,2, \\ldots\\)\n\\(\\frac{1}{n}\\)  \\(k=1,2, \\ldots . n\\)\n\\(\\frac{n+1}{2}\\)\n\\(\\frac{(n+1)[2(2 n+1)-3(n+1)}{12}\\)\n\n\nHipergeométrica\n\\(\\left\\{\\begin{array}{c}N=N_{1}+ \\\\ N_{2} \\\\ p=N_{1} / N\\end{array}\\right.\\)\n\\(\\frac{\\binom{\\mathrm{N}_{1}}{\\mathrm{k}}\\binom{\\mathrm{N}_{2}}{\\mathrm{n}-\\mathrm{k}}}{\\binom{\\mathrm{N}}{\\mathrm{k}}}\\)  \\(\\operatorname{máx}\\left\\{0, \\mathrm{n}-N_{2}\\right\\} \\leq \\mathrm{k} \\leq \\operatorname{mí}\\left\\{N_{1}, n\\right\\}\\)\n\\(n p\\)\n\\(n p(1-p) \\frac{N-n}{N-1}\\)\n\n\nPascal\n\\(0 \\leq p \\leq 1\\)\n\\(p(1-p)^{k}\\)  \\(k=0,1,2, \\ldots\\)\n\\(\\frac{1-p}{p}\\)\n\\(\\frac{1-p}{p^{2}}\\)\n\n\nBinomial  negativa\n\\(0 \\leq p \\leq 1\\)  \\(r&gt;0\\)\n\n\\(\\frac{r(1-p)}{p}\\)\n\\(\\frac{r(1-p)}{p^{2}}\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuciones Notables</span>"
    ]
  },
  {
    "objectID": "03-distribucionesNotables.html#distribuciones-continuas",
    "href": "03-distribucionesNotables.html#distribuciones-continuas",
    "title": "3  Distribuciones Notables",
    "section": "3.2 DISTRIBUCIONES CONTINUAS",
    "text": "3.2 DISTRIBUCIONES CONTINUAS\n\n3.2.1 La distribución Uniforme\nLa distribución Uniforme es el modelo (absolutamente) continuo más simple. Corresponde al caso de una variable aleatoria que sólo puede tomar valores comprendidos entre dos extremos \\(a\\) y \\(b\\), de manera que todos los intervalos de una misma longitud (dentro de \\((a, b)\\) ) tienen la misma probabilidad. También puede expresarse como el modelo probabilístico correspondiente a tomar un número al azar dentro de un intervalo \\((a, b)\\).\nDe la anterior definición se desprende que la función de densidad debe tomar el mismo valor para todos los puntos dentro del intervalo \\((a, b)\\) (y cero fuera del intervalo). Es decir,\n\\[\nf_{X}(x)=\\left\\{\\begin{array}{ll}\n\\frac{1}{b-a} & \\text { si } x \\in(a, b) \\\\\n0 & \\text { si } x \\notin(a, b)\n\\end{array}\\right\\}\n\\]\nGráficamente:\n\nLa función de distribución se obtiene integrando la función de densidad y viene dada por:\n\\[\nF_{X}(x)=P(X \\leq x)=\\left\\{\\begin{array}{ll}\n0 & \\text { si } x \\leq a \\\\\n\\frac{x-a}{b-a} & \\text { si } x \\in(a, b) \\\\\n1 & \\text { si } x \\geq b\n\\end{array}\\right\\}\n\\]\nGráficamente:\nFunción de distribución del modelo uniforme\n\n\n3.2.1.1 Propiedades del modelo Uniforme\n\nSu esperanza vale \\((b+a) / 2\\)\nSu varianza es \\((b-a)^{2} / 12\\)\n\n\n\n3.2.1.2 Una aplicación del modelo Uniforme: el muestreo de Montecarlo\nEn ciertos casos es útil simular el muestreo de una variable aleatoria con una distribución dada. El muestreo de Montecarlo es un procedimiento general para obtener muestras aleatorias de cualquier tipo de variable (discreta o continua) si su función de distribución es conocida o se puede calcular. De hecho, todas las muestras artificiales de Statmedia han sido generadas a través del método de Montecarlo.\nSupongamos que queremos generar una muestra procedente de una variable aleatoria \\(X\\) con función de distribución \\(F(x)\\). El proceso comprende los siguientes pasos:\n\nObtener un valor aleatorio \\(y\\) entre cero y uno. Es decir, obtener una muestra de una distribución Uniforme entre cero y uno. La mayoría de lenguajes de programación incorporan un generador de este tipo.\nConsiderar el valor obtenido como el valor de la función de distribución a generar: \\(y=F(x)\\).\nEl valor \\(x=F^{-1}(y)\\) (la inversa de la función de distribución en el punto \\(y\\) ) es un valor procedente de la distribución de la que deseábamos generar la muestra.\nSi queremos obtener una muestra con \\(n\\) individuos debemos repetir los pasos anteriores \\(n\\) veces.\n\n\n\n3.2.1.3 Generación de una muestra procedente de una distribución Binomial\nSupongamos que queremos simular el experimento de contar el número de caras obtenidas en 5 lanzamientos de una moneda trucada con probabilidad de cara igual a 0,75 . Es decir, queremos obtener una muestra de una distribución Binomial con \\(n=5\\) y \\(p=0,75\\).\nSiguiendo los pasos anteriores deberemos obtener un número al azar entre 0 y 1 (un valor procedente de una distribución Uniforme entre 0 y 1) y si este valor es menor o igual a 0,75 diremos que ha salido cara y, si es superior a 0,75 , cruz. Utiliza el siguiente programa para simular cinco lanzamientos con nuestra moneda trucada:\n\n\n\n3.2.2 La distribución Exponencial\nEste modelo suele utilizarse para variables que describen el tiempo hasta que se produce un determinado suceso.\nSu función de densidad es de la forma:\n\\[\nf(x)=\\left\\{\\begin{array}{lll}\n\\frac{1}{\\alpha} \\exp \\left(-\\frac{x}{\\alpha}\\right) & \\text { si } & x&gt;0 \\\\\n0 & \\text { si } & x \\leq 0\n\\end{array}\\right\\}\n\\]\nComo vemos este modelo depende de un único parámetro \\(\\alpha\\) que debe ser positivo: \\(\\alpha&gt;0\\). A continuación se muestra un programa que nos permite ver cómo cambia la forma de la función de densidad según el parámetro \\(\\alpha\\).\nLa función de distribución se obtiene integrando la de densidad y es de la forma:\n\\[\nF(x)=\\left\\{\\begin{array}{lll}\n1-\\exp \\left(-\\frac{x}{\\alpha}\\right) & \\text { si } & x&gt;0 \\\\\n0 & \\text { si } & x \\leq 0\n\\end{array}\\right\\}\n\\]\nPodemos utilizar el programa siguiente para calcular dicha función de distribución:\n\n3.2.2.1 Propiedades del modelo Exponencial\n\nSu esperanza es \\(\\alpha\\).\nSu varianza es \\(\\alpha^{2}\\).\nUna propiedad importante es la denominada carencia de memoria, que podemos definir así: si la variable \\(X\\) mide el tiempo de vida y sigue una distribución Exponencial, significará que la probabilidad de que siga con vida dentro de 20 años es la misma para un individuo que a fecha de hoy tiene 25 años que para otro que tenga 60 años.\nCuando el número de sucesos por unidad de tiempo sigue una distribución de Poisson de parámetro \\(\\lambda\\) (proceso de Poisson), el tiempo entre dos sucesos consecutivos sigue una distribución Exponencial de parámetro \\(\\alpha=1 / \\lambda\\).\n\n\n\n\n3.2.3 La distribución Normal\nSe trata, sin duda, del modelo continuo más importante en estadística, tanto por su aplicación directa, veremos que muchas variables de interés general pueden describirse por dicho modelo, como por sus propiedades, que han permitido el desarrollo de numerosas técnicas de inferencia estadística. En realidad, el nombre de Normal proviene del hecho de que durante un tiempo se creyó, por parte de médicos y biólogos, que todas las variables naturales de interés seguían este modelo.\nSu función de densidad viene dada por la fórmula:\n\\[\nf(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right\\} \\quad \\text { donde }-\\infty&lt;x&lt;+\\infty\n\\]\nque, como vemos, depende de dos parámetros \\(\\mu\\) (que puede ser cualquier valor real) y \\(\\sigma\\) (que ha de ser positiva). Por esta razón, a partir de ahora indicaremos de forma abreviada que una variable \\(X\\) sigue el modelo Normal así: \\(X \\sim N(\\mu, \\sigma)\\). Por ejemplo, si nos referimos a una distribución Normal con \\(\\mu=0\\) y \\(\\sigma\\) \\(=1\\) lo abreviaremos \\(N(0,1)\\).\nA continuación vemos gráfica de esta función de densidad (podeis probar a cambiar los parámetros):\nComo puedes ver, la función de densidad del modelo Normal tiene forma de campana, la que habitualmente se denomina campana de Gauss. De hecho, a este modelo, también se le conoce con el nombre de distribución gaussiana.\n\n3.2.3.1 Propiedades del modelo Normal\n\nSu esperanza es \\(\\mu\\).\nSu varianza es \\(\\sigma^{2} \\mathrm{y}\\), por tanto, su desviación típica es \\(\\sigma\\).\nEs simétrica respecto a su media \\(\\mu\\), como puede apreciarse en la representación anterior.\nMedia, moda y mediana coinciden \\((\\mu)\\).\nCualquier transformación lineal de una variable con distribución Normal seguirá también el modelo Normal. Si \\(X \\sim N(\\mu, \\sigma)\\) y definimos \\(Y=a X+b(\\operatorname{con} a \\neq 0)\\), entonces \\(Y \\sim N(a \\mu+b,|a| \\sigma)\\). Es decir, la esperanza de \\(Y\\) será \\(a \\mu+b\\) y su desviación típica, \\(|a| \\sigma\\).\nCualquier combinación lineal de variables normales independientes sigue también una distribución Normal. Es decir, dadas \\(n\\) variables aleatorias independientes con distribución \\(X_{i} \\sim\\) \\(N\\left(\\mu_{i}, \\sigma_{i}\\right)\\) para \\(i=1,2, \\ldots, n\\) la combinación lineal: \\(Y=a_{n} X_{n}+a_{n-1} X_{n-1}+\\ldots+a_{1} X_{1}+\\mathrm{a}_{0}\\) sigue también el modelo Normal:\n\n\\[\nY \\approx N\\left(a_{0}+\\sum_{i=1}^{n} a_{i} \\boldsymbol{\\mu}_{i}, \\sqrt{\\sum_{i=1}^{n} a_{i}^{2} \\boldsymbol{\\sigma}^{2}}\\right)\n\\]\n###La función de distribución del modelo Normal\nLa función de distribución del modelo Normal se debería calcular, como en el resto de distribuciones continuas, integrando la función de densidad:\n\\[\nF(x)=P[X \\leq x]=\\int_{-\\infty}^{x} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{(t-\\mu)^{2}}{2 \\sigma^{2}}\\right\\} \\mathrm{dt}\n\\]\nPero nos encontramos con el problema de que no existe ninguna primitiva conocida para esta función, es decir, no sabemos resolver la anterior integral. Sin embargo, si somos incapaces de calcular la función distribución no podremos efectuar ningún cálculo con este modelo. ¿Cómo solucionamos el problema?\nUna primera solución podría consistir en aproximar la integral a través de técnicas de cálculo numérico. Sin embargo, dado que el conjunto de valores que pueden tomar los parámetros \\(\\mu\\) y \\(\\sigma\\) son infinitos, deberíamos repetir el proceso para cada valor diferente de algún parámetro. Afortunadamente, podemos ahorrarnos el esfuerzo aprovechando la propiedad de que cualquier transformación lineal de una variable Normal sigue también el modelo Normal. Por tanto, replantearemos cualquier problema en términos de una Normal concreta, que suele ser la \\(\\mathrm{N}(0,1)\\), de la siguiente manera:\nSi \\(X \\sim N(\\mu, \\sigma)\\) y entonces definimos \\(Z=(\\mathrm{X}-\\mu) / \\sigma\\) se cumplirá que \\(Z \\sim N(0,1)\\)\n\\[\n\\begin{gathered}\n\\text { y, por tanto: } \\\\\nF_{X}(x)=P[X \\leq x]=P\\left[\\frac{X-\\boldsymbol{\\mu}}{\\boldsymbol{\\sigma}} \\leq \\frac{x-\\boldsymbol{\\mu}}{\\boldsymbol{\\sigma}}\\right]=P\\left[Z \\leq \\frac{x-\\boldsymbol{\\mu}}{\\boldsymbol{\\sigma}}\\right]=F_{Z}\\left(\\frac{x-\\boldsymbol{\\mu}}{\\boldsymbol{\\sigma}}\\right)\n\\end{gathered}\n\\]\nA la distribución \\(N(0,1)\\), es decir, la que tiene por media cero y por desviación típica uno, se le denomina Normal reducida o tipificada. En cambio, al proceso de transformación del cálculo de la función de distribución de una Normal cualquiera a través de la Normal tipificada, se le denomina tipificación.\nDebemos remarcar que el proceso de tipificación no resuelve el problema de la inexistencia de la función primitiva correspondiente. Sin embargo, sí es posible, mediante técnicas de cálculo numérico, obtener la integral numérica correspondiente y elaborar unas tablas que podemos consultar. Naturalmente, la tipificación permite que con una sola tabla, la de la \\(N(0,1)\\), tengamos suficiente.\nHoy en día, cada vez se utilizan menos tablas como la mencionada anteriormente, ya que los ordenadores, junto con los abundantes programas estadísticos existentes nos resuelven este problema. Sin embargo, la imposibilidad de integrar analíticamente la función de densidad persiste y, aunque nosotros no seamos conscientes, los programas informáticos realizan el proceso de tipificación para simplificar el problema.\nA continuación se presenta un programa que permite comparar la función de densidad de una distribución Normal cualquiera con la de la Normal tipificada:\n\n\n3.2.3.2 Cálculo de probabilidades del modelo Normal con Statmedia\n\n\n\n\n\n\nAVIS\n\n\n\nPosar un exemple de com fer-ho amb R O buscar si algun Shiny ho fa\n\n\nEl siguiente programa dibuja el área bajo de la función de densidad de una Normal cualquiera, a la izquierda de un valor \\(x\\), es decir, el valor de la función de distribución en el punto \\(x\\), cuyo valor también calcula el programa.\nPara acabar, debemos recordar que Statmedia dispone de una calculadora estadística que también nos permite calcular la función de distribución de cualquier valor para una distribución Normal cualquiera. A continuación se muestra dicha calculadora una vez se ha escogido la opción de calculadora probabilística y, posteriormente, el modelo Normal:\nComo podéis observar, calcula la función de densidad, la de distribución y la inversa de esta última. Además, incluye otras distribuciones ya vistas o que se verán posteriormente.\nPara utilizar esta calculadora sólo tenéis que apretar el botón Calculadora de la barra de navegación.\n\n\n\n3.2.4 La distribución Gamma\nEste modelo es una generalización del modelo Exponencial ya que, en ocasiones, se utiliza para modelar variables que describen el tiempo hasta que se produce p veces un determinado suceso.\nSu función de densidad es de la forma:\n\\[\nf(x)=\\left\\{\\begin{array}{lll}\n\\frac{1}{\\alpha^{p} \\Gamma(p)} e^{-\\frac{x}{\\alpha}} x^{p-1} & \\text { si } & x&gt;0 \\\\\n0 & \\text { si } & x \\leq 0\n\\end{array}\\right\\}\n\\]\nComo vemos, este modelo depende de dos parámetros positivos: \\(\\alpha\\) y p. La función \\(\\Gamma(p)\\) es la denominada función Gamma de Euler que representa la siguiente integral:\n\\[\n\\Gamma(p)=\\int_{0}^{\\infty} x^{p-1} e^{-x} d x\n\\]\nque verifica \\(\\Gamma(p+1)=p \\Gamma(p)\\), con lo que, si \\(p\\) es un número entero positivo, \\(\\Gamma(p+1)=p\\) ! El siguiente programa permite visualizar la forma de la función de densidad de este modelo (para simplificar, se ha restringido al caso en que \\(p\\) es un número entero).\n\n3.2.4.1 Propiedades de la distribución Gamma\n\nSu esperanza es \\(p \\alpha\\).\nSu varianza es \\(p \\alpha^{2}\\)\nLa distribución Gamma \\((\\alpha, p=1)\\) es una distribución Exponencial de parámetro \\(\\alpha\\). Es decir, el modelo Exponencial es un caso particular de la Gamma \\(\\operatorname{con} p=1\\).\nDadas dos variables aleatorias con distribución Gamma y parámetro \\(\\alpha\\) común\n\n\\[\nX \\sim G\\left(\\alpha, p_{1}\\right) \\text { y } Y \\sim G\\left(\\alpha, p_{2}\\right)\n\\]\nse cumplirá que la suma también sigue una distribución Gamma\n\\[\nX+Y \\sim G\\left(\\alpha, p_{1}+p_{2}\\right)\n\\]\nUna consecuencia inmediata de esta propiedad es que, si tenemos \\(k\\) variables aleatorias con distribución Exponencial de parámetro \\(\\alpha\\) (común) e independientes, la suma de todas ellas seguirá una distribución \\(G(\\alpha, k)\\).\n\n\n\n3.2.5 La distribución de Cauchy\nSe trata de un modelo continuo cuya función de densidad es:\n\\[\nf(x)=\\frac{1}{\\pi\\left(1+x^{2}\\right)} \\quad \\text { para } \\quad-\\infty&lt;x&lt;\\infty\n\\]\nCuya integral nos proporciona la función de distribución:\n\\[\nF(x)=\\int_{-\\infty}^{x} \\frac{1}{\\pi\\left(1+t^{2}\\right)} d t=\\frac{1}{\\pi}[\\arctan (t)]_{t=-\\infty}^{t=x}=\\frac{1}{2}+\\frac{\\arctan (x)}{\\pi}\n\\]\nEl siguiente programa permite visualizar la forma de la función de densidad de este modelo y el valor de la función de distribución:\n\n3.2.5.1 Propiedades de la distribución de Cauchy\nSe trata de un ejemplo de variable aleatoria que carece de esperanza (y, por tanto, también de varianza o cualquier otro momento), ya que la integral impropia correspondiente no es convergente:\n\\[\nE(X)=\\int_{-\\infty}^{\\infty} \\frac{x}{\\pi\\left(1+x^{2}\\right)} d x=\\frac{1}{2 \\pi} \\int_{-\\infty}^{\\infty} \\frac{2 x}{1+x^{2}} d x=\\frac{1}{2 \\pi}\\left[\\lim _{x \\rightarrow \\infty} \\ln \\left(x^{2}\\right)-\\lim _{x \\rightarrow-\\infty} \\ln \\left(x^{2}\\right)\\right]=\\frac{1}{2 \\pi}[\\infty-\\infty]\n\\]\ny nos queda una indeterminación. Por tanto, la esperanza de una distribución de Cauchy no existe. Cabe señalar que la función de densidad es simétrica respecto al valor cero (que sería la mediana y la moda), pero al no existir la integral anterior, la esperanza no existe.\n\n\n\n3.2.6 La distribución de Weibull\nSe trata de un modelo continuo asociado a variables del tipo tiempo de vida, tiempo hasta que un mecanismo falla, etc. La función de densidad de este modelo viene dada por:\n\\[\nf(x)=\\left\\{\\begin{array}{ll}\n\\frac{\\beta}{\\alpha}\\left(\\frac{x}{\\alpha}\\right)^{\\beta-1} e^{-\\left(\\frac{x}{\\alpha}\\right)^{\\beta}} & \\text { si } x \\geq 0 \\\\\n0 & \\text { si } x&lt;0\n\\end{array}\\right\\}\n\\]\nque, como vemos, depende de dos parámetros: \\(\\alpha&gt;0\\) y \\(\\beta&gt;0\\), donde \\(\\alpha\\) es un parámetro de escala y \\(\\beta\\) es un parámetro de forma (lo que proporciona una gran flexibilidad a este modelo).\nLa función de distribución se obtiene por la integración de la función de densidad y vale:\n\\[\nF(x)=1-e^{-\\left(\\frac{x}{\\alpha}\\right)^{\\beta}}\n\\]\nEl siguiente programa permite visualizar la forma de la función de densidad de este modelo y el valor de la función de distribución:\n\n3.2.6.1 Propiedades de la distribución Weibull\n\nSi tomamos \\(\\beta=1\\) tenemos una distribución Exponencial.\nSu esperanza vale:\n\n\\[\nE(X)=\\alpha \\Gamma\\left(\\frac{1}{\\boldsymbol{\\beta}}+\\mathbf{1}\\right)\n\\]\n\nSu varianza vale:\n\n\\[\nV(X)=\\alpha^{2}\\left\\{\\Gamma\\left(\\frac{2}{\\beta}+1\\right)-\\left[\\Gamma\\left(\\frac{1}{\\beta}+1\\right)\\right]^{2}\\right\\}\n\\]\ndonde \\(\\Gamma(x)\\) representa la función Gamma de Euler definida anteriormente.\n\n\n\n3.2.7 Tabla resumen de las principales distribuciones continuas\n\n\n\n\n\n\n\n\n\n\nDistribución\nParámetros\nFunción de densidad\nEsperanza\nVarianza\n\n\n\n\nUniforme\n\\(a, b\\)\n\\(\\frac{1}{b-a}\\)  \\(a&lt;x&lt;b\\)\n\\(\\frac{a+b}{2}\\)\n\\(\\frac{(b-a)^{2}}{12}\\)\n\n\nExponencial\n\\(\\alpha&gt;0\\)\n\\(\\frac{1}{\\alpha} \\exp \\left(-\\frac{x}{\\alpha}\\right)\\)  \\(x&gt;0\\)\n\\(\\alpha\\)\n\\(\\alpha^{2}\\)\n\n\nNormal\n\\(-\\infty&lt;\\mu&lt;\\infty\\)  \\(\\sigma&gt;0\\)\n\\(\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right\\}\\)  \\(-\\infty&lt;x&lt;+\\infty\\)\n\\(\\mu\\)\n\\(\\sigma^{2}\\)\n\n\n\n\nCauchy | - | \\(\\frac{1}{\\pi\\left(1+x^{2}\\right)}\\)  \\(-\\infty&lt;\\mathbf{x}&lt;\\infty\\) | – | – |\nWeibull | \\(\\alpha&gt;0\\)  \\(\\beta&gt;0\\) | \\(\\frac{\\boldsymbol{\\beta}}{\\boldsymbol{\\alpha}}\\left(\\frac{x}{\\boldsymbol{\\alpha}}\\right)^{\\beta-1} e^{-\\left(\\frac{x}{\\alpha}\\right)^{\\beta}}\\)  \\(x \\geq 0\\) | \\(\\alpha \\Gamma\\left(\\frac{1}{\\beta}+1\\right)\\) | \\(\\alpha^{2}\\left\\{\\Gamma\\left(\\frac{2}{\\beta}+1\\right)-\\left[\\Gamma\\left(\\frac{1}{\\beta}+1\\right)\\right]^{2}\\right\\}\\) |",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuciones Notables</span>"
    ]
  },
  {
    "objectID": "03-distribucionesNotables.html#la-familia-exponencial-de-distribuciones",
    "href": "03-distribucionesNotables.html#la-familia-exponencial-de-distribuciones",
    "title": "3  Distribuciones Notables",
    "section": "3.3 LA FAMILIA EXPONENCIAL DE DISTRIBUCIONES",
    "text": "3.3 LA FAMILIA EXPONENCIAL DE DISTRIBUCIONES",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distribuciones Notables</span>"
    ]
  },
  {
    "objectID": "04-grandesMuestras.html",
    "href": "04-grandesMuestras.html",
    "title": "4  Grandes muestras",
    "section": "",
    "text": "4.1 Introducción: Aproximaciones asintóticas",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Grandes muestras</span>"
    ]
  },
  {
    "objectID": "04-grandesMuestras.html#introducción-aproximaciones-asintóticas",
    "href": "04-grandesMuestras.html#introducción-aproximaciones-asintóticas",
    "title": "4  Grandes muestras",
    "section": "",
    "text": "4.1.1 Convergencia de variables aleatorias",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Grandes muestras</span>"
    ]
  },
  {
    "objectID": "04-grandesMuestras.html#leyes-de-los-grandes-números",
    "href": "04-grandesMuestras.html#leyes-de-los-grandes-números",
    "title": "4  Grandes muestras",
    "section": "4.2 Leyes de los grandes números",
    "text": "4.2 Leyes de los grandes números",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Grandes muestras</span>"
    ]
  },
  {
    "objectID": "04-grandesMuestras.html#el-teorema-central-del-límite",
    "href": "04-grandesMuestras.html#el-teorema-central-del-límite",
    "title": "4  Grandes muestras",
    "section": "4.3 El teorema central del límite",
    "text": "4.3 El teorema central del límite\nEl teorema central del límite (a partir de ahora, TCL) presenta un doble interés. Por un lado, proporciona a la estadística un resultado crucial para abordar el estudio de la distribución asintótica de muchos tipos de variables aleatorias. Como se verá en próximos capítulos, va a resultar básico en la construcción de contrastes de hipótesis y de intervalos de confianza, dos herramientas esenciales en estadística aplicada.\nAdemás, el TCL proporciona una explicación teórica fundamentada a un fenómeno habitual en experimentos reales: las variables estudiadas presentan muchas veces una distribución empírica aproximadamente normal.\nEl TCL forma parte de un conjunto de propiedades relativas a las convergencias de variables aleatorias. En este tema se estudia sólo un tipo de convergencia, la convergencia en ley, ya que es necesaria para entender el enunciado del TCL. Se descarta, pues, en este documento el estudio de los otros tipos de convergencias (en probabilidad, casi segura, etc.) y el estudio de las leyes de los grandes números.\nPosiblemente el lector con poca formación en análisis matemático hallará alguna dificultad en la primera lectura de la definición de convergencia en ley y en el enunciado del TCL. Si es este el caso, los ejemplos incluidos han de ayudar en su comprensión. Consideramos al TCL un resultado básico con el que hay que familiarizarse, ya que se aplicará repetidamente en los próximos temas.\n\n4.3.1 Sumas de variables aleatorias\nEl TCL estudia el comportamiento de las sumas de variables aleatorias. En temas anteriores se han visto ya ejemplos de sumas de variables aleatorias.\nFormalmente, la suma de dos variables aleatorias corresponde a la siguiente aplicación: si \\(X_{1}\\) y \\(X_{2}\\) son dos variables aleatorias definidas sobre \\(\\Omega\\), la suma es:\n\\[\n\\begin{aligned}\nX_{1}+X_{2}: & \\Omega \\rightarrow \\mathbb{R} \\\\\n& \\omega \\mapsto X_{1}(\\omega)+X_{2}(\\omega)\n\\end{aligned}\n\\]\nLa suma de dos variables puede extenderse sin dificultad a sumas de tres, cuatro,… y, en general, \\(n\\) variables aleatorias.\nEl TCL se ocupa de las sucesiones de variables aleatorias. En el contexto del TCL una sucesión corresponde a un conjunto donde el primer elemento es una variable aleatoria, el segundo elemento es la suma de dos variables aleatorias, el tercero es la suma de tres variables aleatorias, y así sucesivamente.\nUna sucesión es un conjunto de elementos infinitos, que se designan simbólicamente mediante \\(\\left\\{X_{n}\\right\\}\\). Cada uno de los elementos de la sucesión (que es una variable aleatoria) lleva asociada una determinada función de distribución:\n\\[\nX_{n} \\rightarrow F_{n}\n\\]\nAsí pues, la sucesión de variables aleatorias lleva asociada una secuencia paralela de funciones de distribución.\nEn los ejemplos se presentan sumas de variables aleatorias de diferentes tipos.\n\n4.3.1.1 Presentación de los ejemplos\n\nEjemplo 1: sumas de variables binomiales.\nEjemplo 2: sumas de variables Poisson.\nEjemplo 3: sumas de \\(n\\) puntuaciones de dados.\nEjemplo 4: sumas de variables uniformes.\nEjemplo 5: sumas de variables exponenciales.\n\n\n\n\n4.3.2 Definición de convergencia en ley\nLa siguiente definición se ocupa del comportamiento de las sucesiones. Sea \\(\\left\\{X_{n}\\right\\}\\) una sucesión de variables aleatorias, y sea \\(\\left\\{F_{n}\\right\\}\\) la correspondiente sucesión de funciones de distribución. Se dice que \\(\\left\\{X_{n}\\right\\}\\) converge en ley a una variable aleatoria \\(X\\) de función de distribución \\(F\\) si:\n\\[\n\\lim _{n \\rightarrow \\infty} F_{n}(x)=F(x) \\quad \\text { para todo } \\mathrm{x} \\text { donde } F \\text { es contínua. }\n\\]\nSe indica que la sucesión converge en ley mediante el símbolo:\n\\[\nX_{n} \\stackrel{\\mathrm{L}}{\\rightarrow} X\n\\]\nEl significado de la definición es que, al aumentar arbitrariamente \\(n\\), las sucesivas funciones de distribución de la secuencia se aproximan a la distribución \\(F\\) de la variable \\(X\\).\nEn los ejemplos se presentan gráficamente algunas situaciones donde diferentes sucesiones de variables aleatorias convergen en ley a una variable aleatoria normal.\n\n4.3.2.1 Representación gráfica de la convergencia\n\nEjemplo 1: primeros elementos de una sucesión de sumas de variables binomiales.\nEjemplo 2: primeros elementos de una sucesión de sumas de variables Poisson.\nEjemplo 3: primeros elementos de una sucesión de sumas de variables discretas.\nEjemplo 4: primeros elementos de una sucesión de sumas de variables uniformes.\nEjemplo 5: primeros elementos de una sucesión de sumas de variables exponenciales.\n\n\n\n\n4.3.3 Enunciado del teorema central del límite\nA continuación se presenta el enunciado del TCL en la versión de Lindeberg y Lévy. Teorema: Sea \\(X_{1}, X_{2}, \\ldots, X_{n}\\), un conjunto de variables aleatorias independientes idénticamente distribuidas, cada una de ellas con función de distribución \\(F\\), y supongamos que \\(E\\left(X_{k}\\right)\\) \\(=\\mu \\mathrm{y} \\operatorname{var}\\left(X_{k}\\right)=\\sigma^{2}\\) para cualquier elemento del conjunto. Si designamos a la suma normalizada de \\(n\\) términos con el símbolo:\n\\[\nS_{n}^{*}=\\frac{X_{1}+X_{2}+\\cdots+X_{n}-n \\mu}{\\sigma \\sqrt{n}}\n\\]\nentonces la sucesión de sumas normalizadas converge en ley a la variable aleatoria normal tipificada \\(\\mathrm{Z} \\sim N(0,1)\\), es decir:\n\\[\nS_{n}^{*} \\xrightarrow{\\mathrm{L}}\n\\]\nEl teorema anterior tiene dos importantes corolarios:\n\nSi consideramos la suma ordinaria de las \\(n\\) variables aleatorias, es decir, \\(S_{n}=X_{1}+X_{2}+\\ldots+X_{n}\\), entonces la sucesión de sumas ordinarias converge en ley a una normal de media \\(n \\mu\\) y varianza \\(n \\sigma^{2}\\).\nSi consideramos el promedio de las \\(n\\) variables aleatorias, es decir, \\(n^{-1} S_{n}\\), entonces la sucesión de promedios converge en ley a una normal de media \\(\\mu\\) y varianza \\(n^{-1} \\sigma^{2}\\).\n\n\n4.3.3.1 Comentarios al teorema:\n\nLa convergencia a la normal tipificada se produce con cualquier tipo de variable que cumpla las condiciones del teorema, sea discreta o absolutamente continua.\nUn sinónimo para indicar que una sucesión converge en ley a una normal es señalar que es asintóticamente normal.\nEl TCL presenta el comportamiento de sumas infinitas de variables aleatorias. Veremos posteriormente como interpretar el resultado para valores finitos.\nExisten otras versiones del TCL dónde se relajan las condiciones de la versión de Lindeberg y Lévy, que, como se ha visto, obliga a las variables aleatorias a tener idénticas medias y varianzas. Dichas versiones del TCL necesitan el conocimiento de conceptos matemáticos que exceden el nivel al que se orienta Statmedia, y por esta razón se omite su enunciado.\n\n\n\n\n4.3.4 Aplicación del TCL a los ejemplos\n\nEjemplo 1: normalidad asintótica de la Binomial.\nEjemplo 2: normalidad asintótica de la Poisson.\nEjemplo 3: normalidad asintótica de la suma de puntuaciones de un dado.\nEjemplo 4: normalidad asintótica de la suma de uniformes.\nEjemplo 5: normalidad asintótica de la suma de exponenciales.\n\n\n\n4.3.5 Casos particulares más notables\nAunque el TCL tiene multitud de casos particulares interesantes, son especialmente relevantes para el desarrollo de los próximos temas los siguientes casos:\n\n4.3.5.1 Promedio de \\(\\boldsymbol{n}\\) variables aleatorias\nAl considerar \\(n\\) variables independientes, todas con la misma distribución, cada una de ellas con esperanza igual a \\(\\mu\\) y varianza igual a \\(\\sigma^{2}\\), el promedio es asintóticamente normal con media \\(\\mu\\) y varianza \\(n^{-1} \\sigma^{2}\\). Este resultado proporciona una distribución asintótica a la media de \\(n\\) observaciones en el muestreo aleatorio simple que se estudiará en el próximo tema.\n\n\n4.3.5.2 Binomial de parámetros \\(n\\) y \\(p\\)\nEs asintóticamente normal con media \\(n p\\) y varianza \\(n p\\) (1-p). Históricamente (de Moivre, 1733), es el primer resultado demostrado de convergencia a una normal.\n\n\n4.3.5.3 Poisson de parámetro \\(n \\lambda\\)\nEs asintóticamente normal con media \\(n \\lambda\\) y varianza \\(n \\lambda\\).\n\n\n\n\n4.3.6 Interpretación del teorema central del límite\nEl TCL hace referencia a sucesiones infinitas, por tanto, la igualdad de las distribuciones se alcanza sólo en el límite, y hace mención a una distribución final teórica o de referencia.\nSin embargo, puede utilizarse esta distribución final de referencia para aproximar distribuciones correspondientes a sumas finitas. Algunos casos particulares importantes (binomial, Poisson, etc.) alcanzan grados de aproximación suficientes para sumas con no demasiados términos.\nLos resultados que se indican a continuación son, por tanto, aproximaciones que se consideran usualmente suficientes, pero conllevan errores numéricos de aproximación.\n\nBinomial: aproximar si \\(n \\geq 30\\) y \\(0.1 \\leq p \\leq 0.9\\) a una normal de media \\(n p\\), varianza \\(n p(1-p)\\). Ver aquí más detalles.\nPoisson: aproximar si \\(\\lambda \\geq 10\\) a una normal de media \\(\\lambda\\) y varianza \\(\\lambda\\). Ver aquí más detalles.\n\nPara evaluar aproximadamente el error cometido en las aproximaciones, puede consultarse los cuadros gráficos de los ejemplos de este tema.\nEl TCL permite aproximar funciones de distribución, independientemente del carácter (continuo o discreto) de las variables sumadas. No sirve, por tanto, para aproximar la funciones de densidad discretas por una normal. En el caso continuo sí puede establecerse también una convergencia de las densidades asociadas.\nFinalmente, es conveniente mencionar que existen resultados teóricos que permiten estudiar la velocidad de convergencia de una suma de variables aleatorias a la normal, sin embargo la dificultad técnica que conllevan trasciende el nivel marcado para el conjunto de documentos marcado para Statmedia.\n\n\n4.3.7 Aproximaciones y errores numéricos\n\nEjemplo 1: error en la aproximación de la binomial.\nEjemplo 2: error en la aproximación de la Poisson.\nEjemplo 3: error en la aproximación de la suma de puntuaciones de un dado.\nEjemplo 4: error en la aproximación de la suma de uniformes.\nEjemplo 5: error en la aproximación de la suma de exponenciales.\n\n\n\n4.3.8 Acerca de las variables aproximadamente normales\nEn general, cuando se estudia en experimentos reales una determinada variable no se conoce su distribución teórica. Sin embargo, puede establecerse su distribución empirica a partir de una muestra más o menos amplia.\nUna forma habitual de presentar la distribución empírica es construir el histograma de clases de dicha variable. Es un hecho conocido desde el siglo XIX que esta distribución empírica presenta muchas veces una forma que es aproximadamente normal. Por ejemplo, al realizar un estudio sobre el peso de adultos varones de dieciocho años en Catalunya, se observó la distribución siguiente en la muestra:\n\nEl TCL permite dar una explicación a este fenómeno. La variable peso de un adulto viene determinada en cada individuo por la conjunción de multitud de diferentes factores. Algunos de estos factores son ambientales (dietas, ejercicio, enfermedades, etc.) y otros son congénitos. Con el nivel actual de conocimiento no se pueden desglosar completamente todos los factores que intervienen, pero puede aceptarse en cambio que la variable peso es el resultante de la suma de diferentes variables primarias, congénitas o ambientales, y que posiblemente no todas tienen el mismo grado de influencia. Seguramente, estas variables primarias tampoco tienen la misma media, varianza o, incluso, la misma distribución.\nLa versión del TCL que se ha presentado aquí exige estas condiciones para la convergencia a la normal, pero, como ya se ha comentado antes otras versiones más elaboradas del TCL permiten modelar la suma de variables de forma menos restringida. En este contexto, al considerar la variable peso como una suma más o menos extensa (pero finita) de diferentes variables primarias, es esperable que ocurra que la variable resultante, el peso, siga una distribución aproximadamente normal.\nDe forma similar es explicable la normalidad aproximada que se observa en muchas variables biométricas (pesos, alturas, longitudes, concentraciones de metabolitos, distribuciones de edad, etc.) así cómo en muchos otros contextos (distribución de rentas, errores de medición, etc.). A pesar de esta ubicuidad de la distribución normal, el lector no debe inferir que es forzosamente, ni mucho menos, la distribución de referencia en todo estudio aplicado.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Grandes muestras</span>"
    ]
  },
  {
    "objectID": "05-vectoresAleatorios.html",
    "href": "05-vectoresAleatorios.html",
    "title": "5  Distribuciones de probabilidad multidimensionales",
    "section": "",
    "text": "5.1 Variables aleatorias multidimensionales.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Distribuciones de probabilidad multidimensionales</span>"
    ]
  },
  {
    "objectID": "05-vectoresAleatorios.html#distribuciones-conjuntas-marginales-y-condicionales.",
    "href": "05-vectoresAleatorios.html#distribuciones-conjuntas-marginales-y-condicionales.",
    "title": "5  Distribuciones de probabilidad multidimensionales",
    "section": "5.2 Distribuciones conjuntas, marginales y condicionales,.",
    "text": "5.2 Distribuciones conjuntas, marginales y condicionales,.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Distribuciones de probabilidad multidimensionales</span>"
    ]
  },
  {
    "objectID": "05-vectoresAleatorios.html#valores-esperados-covariancia-y-correlación.",
    "href": "05-vectoresAleatorios.html#valores-esperados-covariancia-y-correlación.",
    "title": "5  Distribuciones de probabilidad multidimensionales",
    "section": "5.3 Valores esperados, covariancia y correlación.",
    "text": "5.3 Valores esperados, covariancia y correlación.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Distribuciones de probabilidad multidimensionales</span>"
    ]
  },
  {
    "objectID": "05-vectoresAleatorios.html#independencia-de-variables-aleatorias",
    "href": "05-vectoresAleatorios.html#independencia-de-variables-aleatorias",
    "title": "5  Distribuciones de probabilidad multidimensionales",
    "section": "5.4 Independencia de variables aleatorias",
    "text": "5.4 Independencia de variables aleatorias",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Distribuciones de probabilidad multidimensionales</span>"
    ]
  },
  {
    "objectID": "05-vectoresAleatorios.html#distribuciones-multivariantes-multinomial-y-normal-bivariante.",
    "href": "05-vectoresAleatorios.html#distribuciones-multivariantes-multinomial-y-normal-bivariante.",
    "title": "5  Distribuciones de probabilidad multidimensionales",
    "section": "5.5 Distribuciones multivariantes: multinomial y normal bivariante.",
    "text": "5.5 Distribuciones multivariantes: multinomial y normal bivariante.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Distribuciones de probabilidad multidimensionales</span>"
    ]
  },
  {
    "objectID": "06-introInferencia.html",
    "href": "06-introInferencia.html",
    "title": "6  Introducción a la inferencia estadística",
    "section": "",
    "text": "6.1 Los problemas de la inferencia estadística.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introducción a la inferencia estadística</span>"
    ]
  },
  {
    "objectID": "06-introInferencia.html#muestreo-y-distribuciones-en-el-muestreo.",
    "href": "06-introInferencia.html#muestreo-y-distribuciones-en-el-muestreo.",
    "title": "6  Introducción a la inferencia estadística",
    "section": "6.2 Muestreo y distribuciones en el muestreo.",
    "text": "6.2 Muestreo y distribuciones en el muestreo.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introducción a la inferencia estadística</span>"
    ]
  },
  {
    "objectID": "06-introInferencia.html#la-verosimilitud-y-su-papel-en-la-inferencia-estadística",
    "href": "06-introInferencia.html#la-verosimilitud-y-su-papel-en-la-inferencia-estadística",
    "title": "6  Introducción a la inferencia estadística",
    "section": "6.3 La verosimilitud y su papel en la inferencia estadística",
    "text": "6.3 La verosimilitud y su papel en la inferencia estadística",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introducción a la inferencia estadística</span>"
    ]
  },
  {
    "objectID": "06-introInferencia.html#el-problema-de-la-estimación.-tipos-de-estimadores.",
    "href": "06-introInferencia.html#el-problema-de-la-estimación.-tipos-de-estimadores.",
    "title": "6  Introducción a la inferencia estadística",
    "section": "6.4 El problema de la estimación. Tipos de estimadores.",
    "text": "6.4 El problema de la estimación. Tipos de estimadores.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introducción a la inferencia estadística</span>"
    ]
  },
  {
    "objectID": "06-introInferencia.html#métodos-de-obtención-de-estimadores.-estimadores-máximo-verosímiles-y-estimadores-bayesianos.",
    "href": "06-introInferencia.html#métodos-de-obtención-de-estimadores.-estimadores-máximo-verosímiles-y-estimadores-bayesianos.",
    "title": "6  Introducción a la inferencia estadística",
    "section": "6.5 Métodos de obtención de estimadores. Estimadores máximo verosímiles y estimadores bayesianos.",
    "text": "6.5 Métodos de obtención de estimadores. Estimadores máximo verosímiles y estimadores bayesianos.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introducción a la inferencia estadística</span>"
    ]
  },
  {
    "objectID": "06-introInferencia.html#propiedades-de-los-estimadores.",
    "href": "06-introInferencia.html#propiedades-de-los-estimadores.",
    "title": "6  Introducción a la inferencia estadística",
    "section": "6.6 Propiedades de los estimadores.",
    "text": "6.6 Propiedades de los estimadores.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introducción a la inferencia estadística</span>"
    ]
  },
  {
    "objectID": "07-estimacion.html",
    "href": "07-estimacion.html",
    "title": "7  Estimación por intérvalos",
    "section": "",
    "text": "7.1 Preliminares: estimación del error estándar e Introducción al bootstrap",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estimación por intérvalos</span>"
    ]
  },
  {
    "objectID": "07-estimacion.html#estimadores-por-intervalo-intervalos-de-confianza",
    "href": "07-estimacion.html#estimadores-por-intervalo-intervalos-de-confianza",
    "title": "7  Estimación por intérvalos",
    "section": "7.2 Estimadores por intervalo: intervalos de confianza",
    "text": "7.2 Estimadores por intervalo: intervalos de confianza",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estimación por intérvalos</span>"
    ]
  },
  {
    "objectID": "07-estimacion.html#intervalos-de-confianza-para-características-de-una-población-normal-media-varianza",
    "href": "07-estimacion.html#intervalos-de-confianza-para-características-de-una-población-normal-media-varianza",
    "title": "7  Estimación por intérvalos",
    "section": "7.3 Intervalos de confianza para características de una población normal (media, varianza),",
    "text": "7.3 Intervalos de confianza para características de una población normal (media, varianza),",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estimación por intérvalos</span>"
    ]
  },
  {
    "objectID": "07-estimacion.html#intervalos-de-confianza-bootstrap.",
    "href": "07-estimacion.html#intervalos-de-confianza-bootstrap.",
    "title": "7  Estimación por intérvalos",
    "section": "7.4 Intervalos de confianza bootstrap.",
    "text": "7.4 Intervalos de confianza bootstrap.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estimación por intérvalos</span>"
    ]
  },
  {
    "objectID": "07-estimacion.html#intervalos-de-confianza-para-proporciones-binomiales",
    "href": "07-estimacion.html#intervalos-de-confianza-para-proporciones-binomiales",
    "title": "7  Estimación por intérvalos",
    "section": "7.5 Intervalos de confianza para proporciones binomiales",
    "text": "7.5 Intervalos de confianza para proporciones binomiales",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estimación por intérvalos</span>"
    ]
  },
  {
    "objectID": "07-estimacion.html#intervalos-de-confianza-para-parámetros-en-muestra-grandes-y-para-casos-generales-tasas-or",
    "href": "07-estimacion.html#intervalos-de-confianza-para-parámetros-en-muestra-grandes-y-para-casos-generales-tasas-or",
    "title": "7  Estimación por intérvalos",
    "section": "7.6 Intervalos de confianza para parámetros en muestra grandes y para casos generales (tasas, OR, …)",
    "text": "7.6 Intervalos de confianza para parámetros en muestra grandes y para casos generales (tasas, OR, …)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estimación por intérvalos</span>"
    ]
  },
  {
    "objectID": "07-estimacion.html#aplicaciones-cálculo-del-tamaño-muestral",
    "href": "07-estimacion.html#aplicaciones-cálculo-del-tamaño-muestral",
    "title": "7  Estimación por intérvalos",
    "section": "7.7 Aplicaciones: cálculo del tamaño muestral",
    "text": "7.7 Aplicaciones: cálculo del tamaño muestral",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estimación por intérvalos</span>"
    ]
  },
  {
    "objectID": "08-pruebasHipotesis.html",
    "href": "08-pruebasHipotesis.html",
    "title": "8  Pruebas de hipótesis",
    "section": "",
    "text": "8.1 Conceptos básicos: pruebas de hipótesis y de significación, pruebas unilaterales y bilaterales, tipos de error, valores críticos de test y p-valores",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "08-pruebasHipotesis.html#potencia-de-un-test.-cálculos-de-potencia-y-de-tamaño-de-la-muestra.-tamaño-del-efecto.",
    "href": "08-pruebasHipotesis.html#potencia-de-un-test.-cálculos-de-potencia-y-de-tamaño-de-la-muestra.-tamaño-del-efecto.",
    "title": "8  Pruebas de hipótesis",
    "section": "8.2 Potencia de un test. Cálculos de potencia y de tamaño de la muestra. Tamaño del efecto.",
    "text": "8.2 Potencia de un test. Cálculos de potencia y de tamaño de la muestra. Tamaño del efecto.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "08-pruebasHipotesis.html#métodos-de-construcción-de-tests.",
    "href": "08-pruebasHipotesis.html#métodos-de-construcción-de-tests.",
    "title": "8  Pruebas de hipótesis",
    "section": "8.3 Métodos de construcción de tests.",
    "text": "8.3 Métodos de construcción de tests.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "08-pruebasHipotesis.html#problemas-asociados-al-uso-de-tests-estadísticos.-la-crisis-de-la-significación",
    "href": "08-pruebasHipotesis.html#problemas-asociados-al-uso-de-tests-estadísticos.-la-crisis-de-la-significación",
    "title": "8  Pruebas de hipótesis",
    "section": "8.4 Problemas asociados al uso de tests estadísticos. La crisis de la significación",
    "text": "8.4 Problemas asociados al uso de tests estadísticos. La crisis de la significación",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-inferenciaAplicada.html",
    "href": "09-inferenciaAplicada.html",
    "title": "9  Inferencia Aplicada",
    "section": "",
    "text": "9.1 Pruebas de normalidad.Pruebas gráficas. El test de Shapiro-Wilks",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Inferencia Aplicada</span>"
    ]
  },
  {
    "objectID": "09-inferenciaAplicada.html#pruebas-de-hipótesis-para-constrastar-variables-cuantitativas-pruebas-paramètricas-t-test-y-anova",
    "href": "09-inferenciaAplicada.html#pruebas-de-hipótesis-para-constrastar-variables-cuantitativas-pruebas-paramètricas-t-test-y-anova",
    "title": "9  Inferencia Aplicada",
    "section": "9.2 Pruebas de hipótesis para constrastar variables cuantitativas: pruebas paramètricas t-test y Anova",
    "text": "9.2 Pruebas de hipótesis para constrastar variables cuantitativas: pruebas paramètricas t-test y Anova",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Inferencia Aplicada</span>"
    ]
  },
  {
    "objectID": "09-inferenciaAplicada.html#pruebas-de-hipótesis-para-constrastar-variables-cuantitativas-pruebas-de-hipótesis-no-paramétricas-de-wilcoxon-y-kruskal-wallis",
    "href": "09-inferenciaAplicada.html#pruebas-de-hipótesis-para-constrastar-variables-cuantitativas-pruebas-de-hipótesis-no-paramétricas-de-wilcoxon-y-kruskal-wallis",
    "title": "9  Inferencia Aplicada",
    "section": "9.3 Pruebas de hipótesis para constrastar variables cuantitativas: pruebas de hipótesis no paramétricas de Wilcoxon y Kruskal-Wallis",
    "text": "9.3 Pruebas de hipótesis para constrastar variables cuantitativas: pruebas de hipótesis no paramétricas de Wilcoxon y Kruskal-Wallis",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Inferencia Aplicada</span>"
    ]
  },
  {
    "objectID": "09-inferenciaAplicada.html#contrastes-para-datos-categóricos.-pruebas-binomiales-ji-cuadrado-y-test-de-fisher.",
    "href": "09-inferenciaAplicada.html#contrastes-para-datos-categóricos.-pruebas-binomiales-ji-cuadrado-y-test-de-fisher.",
    "title": "9  Inferencia Aplicada",
    "section": "9.4 Contrastes para datos categóricos. Pruebas binomiales, ji cuadrado y test de Fisher.",
    "text": "9.4 Contrastes para datos categóricos. Pruebas binomiales, ji cuadrado y test de Fisher.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Inferencia Aplicada</span>"
    ]
  },
  {
    "objectID": "09-inferenciaAplicada.html#riesgo-relativo-y-razón-de-odds",
    "href": "09-inferenciaAplicada.html#riesgo-relativo-y-razón-de-odds",
    "title": "9  Inferencia Aplicada",
    "section": "9.5 Riesgo relativo y razón de «odds»",
    "text": "9.5 Riesgo relativo y razón de «odds»",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Inferencia Aplicada</span>"
    ]
  },
  {
    "objectID": "10-computerintensive.html",
    "href": "10-computerintensive.html",
    "title": "10  Computación Intensiva y Multiple Testing",
    "section": "",
    "text": "10.1 Tests de permutaciones; ¿Qué?, ¿Cuándo?, ¿Cómo?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Computación Intensiva y _Multiple Testing_</span>"
    ]
  },
  {
    "objectID": "10-computerintensive.html#el-bootstrap-en-contraste-de-hipótesis",
    "href": "10-computerintensive.html#el-bootstrap-en-contraste-de-hipótesis",
    "title": "10  Computación Intensiva y Multiple Testing",
    "section": "10.2 El bootstrap en contraste de hipótesis",
    "text": "10.2 El bootstrap en contraste de hipótesis",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Computación Intensiva y _Multiple Testing_</span>"
    ]
  },
  {
    "objectID": "10-computerintensive.html#el-problema-de-las-comparaciones-múltiples",
    "href": "10-computerintensive.html#el-problema-de-las-comparaciones-múltiples",
    "title": "10  Computación Intensiva y Multiple Testing",
    "section": "10.3 El problema de las comparaciones múltiples",
    "text": "10.3 El problema de las comparaciones múltiples",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Computación Intensiva y _Multiple Testing_</span>"
    ]
  },
  {
    "objectID": "10-computerintensive.html#métodos-de-control-de-error-fwer-y-fdr",
    "href": "10-computerintensive.html#métodos-de-control-de-error-fwer-y-fdr",
    "title": "10  Computación Intensiva y Multiple Testing",
    "section": "10.4 Métodos de control de error: FWER y FDR",
    "text": "10.4 Métodos de control de error: FWER y FDR",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Computación Intensiva y _Multiple Testing_</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fundamentos de Inferencia Estadistica",
    "section": "",
    "text": "Presentación",
    "crumbs": [
      "Presentación"
    ]
  },
  {
    "objectID": "index.html#objetivo",
    "href": "index.html#objetivo",
    "title": "Fundamentos de Inferencia Estadistica",
    "section": "Objetivo",
    "text": "Objetivo\nEl objetivo de estas notas es presentar un material de soporte para la asignatura de “Inferencia Estadística” del Máster interuniversitario de Bioiestadística y Bioinformática impartido conjuntamente por la Universitat Oberta de Catalunya (UOC) y la Universidad de Barcelona (UB).\nEsta asignatura adolece de las características habituales de las asignaturas de posgrado, y especialmente de un posgrado de estadística (y bioinformática), que muestran algunas de las cosas que no debe de ser esta asignatura:\n\nNo puede ser un primer curso de estadística, porque se supone que los estudiantes del máster ya lo han cursado en sus grados. Por no decir que, a quien viene a especializarse en estadística se le puede suponer una base mínima.\nTampoco debe ser como los segundos cursos de estadística de algunos grados, que tratan temas como la regresión, el diseño de experimentos o el análisis multivariante, porque esto ya se trata en diversas asignaturas del máster.\n\n¿Que debemos pues esperar que sea este curso?\n\nPuestos a pedir, este curso debería servir para repasar y consolidar los conceptos básicos que la mayoría de estudiantes traerán consigo.\nAdemás, y sobretodo, debe proporcionar una visión general, lo más completa posible dentro de las limitaciones de tiempo, del campo de la inferencia estadística\nY, naturalmente, esto significa proporcionar aquellos conceptos sobre los que se apoyaran muchas de las restantes asignaturas como “Regresión modelos y métodos”, “Diseño de Experimentos”, “Análisis Multivariante”, “Análisis de la Supervivencia” o “Análisis de datos ómicos”.",
    "crumbs": [
      "Presentación"
    ]
  },
  {
    "objectID": "index.html#prerequisitos-y-organización-del-material",
    "href": "index.html#prerequisitos-y-organización-del-material",
    "title": "Fundamentos de Inferencia Estadistica",
    "section": "Prerequisitos y organización del material",
    "text": "Prerequisitos y organización del material\nUno de los problemas “eternos” en el estudio de la estadística ha sido siempre la falta de acuerdo, entre la comunidad de docentes, de cual debería ser el nivel matemático a que se impartan los cursos.\nEn los cursos de pre-grado ha habido un cierto consenso, y con los años el nivel de formalismo ha disminuido, incluso en estudios de tipo “STEM”, tendiendo a centrarse en la aplicación de los conceptos, por ejemplo usando R, más que en un tratamiento formal (“matemático”) de los mismos.\nAunque esto puede ser práctico para aquellos estudios en los que la estadística és una asignatura de un grado, es también obvio que dicha aproximación no permite profundizar en muchos de los puntos que se tratan.\nEs por ello que en este curso seguiremos la indicación habitual en cursos similares de asumir que el estudiante:\n\nSe siente comodo con el lenguaje algebráico, desarrollo de expresiones, sumatorios etc.\nEstá familiarizado con el cálculo diferencial en una o varias variables, aunque esta familiaridad no será imprescindible para seguir la mayoría de los contenidos del curso.\nConoce el lenguaje estadístico R, que en muchas ocasiones nos ofrecerá una solución directa a los problemas de cálculo.",
    "crumbs": [
      "Presentación"
    ]
  },
  {
    "objectID": "index.html#referencias",
    "href": "index.html#referencias",
    "title": "Fundamentos de Inferencia Estadistica",
    "section": "Referencias",
    "text": "Referencias\nLos prerequisitos anteriores corresponden básicamente a las matemáticas del bachilerato. Algunas funetes adiconales pueden ser:\n\nIniciación a las matemáticas para la ingeniería. M. Besalú y Joana Villalonga\n\nColección de (100) videos de soporte a las matemáticas para la ingeniería",
    "crumbs": [
      "Presentación"
    ]
  },
  {
    "objectID": "index.html#el-proyecto-statmedia",
    "href": "index.html#el-proyecto-statmedia",
    "title": "Fundamentos de Inferencia Estadistica",
    "section": "El proyecto Statmedia",
    "text": "El proyecto Statmedia\nStatmedia es un grupo de innovación docente de la Universidad de Barcelona, cuyo objetivo es desarrollar nuevas herramientas que ayuden en la enseñanza de la estadística aplicada, mejorando así el rendimiento académico de los alumnos y su motivación hacia la estadística.\nPartiendo de la idea que el aprendizaje debe basarse en casos prácticos para motivar y fomentar la participación de los estudiantes. Se desarrolló primer proyecto, Statmedia I, un texto multimedia de estadística que además de los contenidos, relativamente ampliados, para un curso de introducción a la estadística, incorporaba:\n\nUna serie de casos para motivar e ilustrar los conceptos introducidos.\nUn conjunto de gadgets interactivos con los que interactuar y experimentar y\nEjercicios de respuesta múltiple para verificar los conceptos trabajados.\n\nAunque el proyecto Statmedia ha seguido evolucionando en múltiples direcciones, Statmedia I, como tantos otros, no sobrevivió al desarrollo tecnológico, y la evolución (o decadencia) del lenguaje Java lo llevó a dejar de ser funcional.\nPara estos apuntes hemos recuperado, y en ocasiones adaptado o modificado, algunos de los contenidos de Statmedia I, que habían estado escritos con gran pulcritud. Esto se ha hecho siguiendo las indicaciones de la licencia (CC-Share-alike) que permite adaptar contenidos atribuyendolo a sus autores y citando la fuente.\nLos gadgets originales ya no son funcionales pero muchos de ellos han sido re-escritos en R como aplicaciones Shiny (disponibles en: https://grbio.upc.edu/en/software/teaching_apps) y se enlazaran desde los puntos necesarios del texto.\nDejando aparte (además) de la licencia, vaya nuestro agradecimiento explícito al equipo de profesores del Departamento de Estadística de la Universidad de Barcelona, redactor de la versión inicial del proyecto, que es la que hemos utilizado: Antonio Arcas Pons, Miquel calvo Llorca, Antonio Miñarro Alonso, Sergi Civit Vives y Angel Vilarroya del Campo.\nAntoni Arcas, Antonio Miñarro and Miguel Calvo (2008) Statmedia projects in Statistical Education",
    "crumbs": [
      "Presentación"
    ]
  },
  {
    "objectID": "index.html#otros-materiales-utilizados",
    "href": "index.html#otros-materiales-utilizados",
    "title": "Fundamentos de Inferencia Estadistica",
    "section": "Otros materiales utilizados",
    "text": "Otros materiales utilizados\n\nAlex Sanchez y Francesc Carmona (2002). Apunts d’Estadística Matemàtica Licencia CC0 1.0 Universal\nMolina Peralta, I. and García-Portugués, E. (2024). A First Course on Statistical Inference. Version 2.4.1. ISBN 978-84-09-29680-4. Licencia CC BY-NC-ND 4.0\nPeter K. Dunn (2024) The theory of distributions. Licencia CC BY-NC-ND 4.0",
    "crumbs": [
      "Presentación"
    ]
  }
]